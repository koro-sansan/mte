//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0
// _ZZ83Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0E121T_cast_T_multiply_T_multiply_T_cast_T_add_T_add_input_4_T_multiply_T_multiply_input_0_input_1_input_7_input_12_red_shared has been demoted
// _ZZ83Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0E8red_buf1 has been demoted

.visible .entry Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0(
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_0,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_1,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_2,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_3,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_4,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_5,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_6,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_7,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_8
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<73>;
	.reg .f32 	%f<115>;
	.reg .b32 	%r<30>;
	.reg .b64 	%rd<30>;
	// demoted variable
	.shared .align 4 .b8 _ZZ83Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0E121T_cast_T_multiply_T_multiply_T_cast_T_add_T_add_input_4_T_multiply_T_multiply_input_0_input_1_input_7_input_12_red_shared[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ83Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0E8red_buf1[4096];

	ld.param.u64 	%rd10, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_0];
	ld.param.u64 	%rd11, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_1];
	ld.param.u64 	%rd12, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_2];
	ld.param.u64 	%rd13, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_3];
	ld.param.u64 	%rd14, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_4];
	ld.param.u64 	%rd9, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_5];
	ld.param.u64 	%rd15, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_7];
	ld.param.u64 	%rd16, [Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0_param_8];
	cvta.to.global.u64 	%rd17, %rd14;
	mov.u32 	%r9, %ctaid.x;
	shl.b32 	%r10, %r9, 16;
	mov.u32 	%r1, %tid.y;
	shl.b32 	%r11, %r1, 10;
	mov.u32 	%r12, %ctaid.y;
	shl.b32 	%r2, %r12, 7;
	shl.b32 	%r13, %r9, 6;
	add.s32 	%r14, %r10, %r11;
	add.s32 	%r15, %r14, %r2;
	mov.u32 	%r3, %tid.x;
	add.s32 	%r16, %r15, %r3;
	cvta.to.global.u64 	%rd18, %rd12;
	mul.wide.s32 	%rd19, %r16, 4;
	add.s64 	%rd1, %rd18, %rd19;
	add.s32 	%r17, %r13, %r1;
	cvta.to.global.u64 	%rd20, %rd10;
	mul.wide.s32 	%rd21, %r17, 4;
	add.s64 	%rd2, %rd20, %rd21;
	cvta.to.global.u64 	%rd22, %rd11;
	add.s64 	%rd3, %rd22, %rd19;
	ld.global.nc.f32 	%f3, [%rd3];
	ld.global.nc.f32 	%f4, [%rd2];
	mul.f32 	%f5, %f4, %f3;
	ld.global.nc.f32 	%f6, [%rd1];
	fma.rn.f32 	%f7, %f5, 0f3B000000, %f6;
	cvta.to.global.u64 	%rd23, %rd13;
	add.s64 	%rd4, %rd23, %rd21;
	ld.global.nc.f32 	%f8, [%rd4];
	add.f32 	%f1, %f8, %f7;
	// inline asm
	{  cvt.rn.f16.f32 %rs1, %f1;}

	// inline asm
	cvta.to.global.u64 	%rd24, %rd15;
	mul.wide.s32 	%rd25, %r16, 2;
	add.s64 	%rd5, %rd24, %rd25;
	st.global.u16 	[%rd5], %rs1;
	mov.f32 	%f2, 0f3FA00000;
	// inline asm
	{  cvt.rn.f16.f32 %rs2, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs3,%rs1,%rs2;
}
	// inline asm
	add.s64 	%rd6, %rd17, %rd25;
	ld.global.nc.u16 	%rs8, [%rd6];
	// inline asm
	{mul.f16 %rs6,%rs3,%rs8;
}
	// inline asm
	cvta.to.global.u64 	%rd26, %rd16;
	add.s64 	%rd7, %rd26, %rd25;
	st.global.u16 	[%rd7], %rs6;
	shl.b32 	%r18, %r3, 2;
	mov.u32 	%r19, _ZZ83Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0E121T_cast_T_multiply_T_multiply_T_cast_T_add_T_add_input_4_T_multiply_T_multiply_input_0_input_1_input_7_input_12_red_shared;
	add.s32 	%r4, %r19, %r18;
	setp.ne.s32	%p3, %r1, 0;
	@%p3 bra 	BB0_2;

	mov.u32 	%r20, 0;
	st.shared.u32 	[%r4], %r20;

BB0_2:
	ld.global.nc.f32 	%f23, [%rd3+32768];
	ld.global.nc.f32 	%f24, [%rd2+32];
	mul.f32 	%f25, %f24, %f23;
	ld.global.nc.f32 	%f26, [%rd1+32768];
	fma.rn.f32 	%f27, %f25, 0f3B000000, %f26;
	ld.global.nc.f32 	%f28, [%rd4+32];
	add.f32 	%f9, %f28, %f27;
	// inline asm
	{  cvt.rn.f16.f32 %rs9, %f9;}

	// inline asm
	st.global.u16 	[%rd5+16384], %rs9;
	// inline asm
	{  cvt.rn.f16.f32 %rs10, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs11,%rs9,%rs10;
}
	// inline asm
	ld.global.nc.u16 	%rs16, [%rd6+16384];
	// inline asm
	{mul.f16 %rs14,%rs11,%rs16;
}
	// inline asm
	st.global.u16 	[%rd7+16384], %rs14;
	ld.global.nc.f32 	%f29, [%rd3+65536];
	ld.global.nc.f32 	%f30, [%rd2+64];
	mul.f32 	%f31, %f30, %f29;
	ld.global.nc.f32 	%f32, [%rd1+65536];
	fma.rn.f32 	%f33, %f31, 0f3B000000, %f32;
	ld.global.nc.f32 	%f34, [%rd4+64];
	add.f32 	%f11, %f34, %f33;
	// inline asm
	{  cvt.rn.f16.f32 %rs17, %f11;}

	// inline asm
	st.global.u16 	[%rd5+32768], %rs17;
	// inline asm
	{  cvt.rn.f16.f32 %rs18, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs19,%rs17,%rs18;
}
	// inline asm
	ld.global.nc.u16 	%rs24, [%rd6+32768];
	// inline asm
	{mul.f16 %rs22,%rs19,%rs24;
}
	// inline asm
	st.global.u16 	[%rd7+32768], %rs22;
	ld.global.nc.f32 	%f35, [%rd3+98304];
	ld.global.nc.f32 	%f36, [%rd2+96];
	mul.f32 	%f37, %f36, %f35;
	ld.global.nc.f32 	%f38, [%rd1+98304];
	fma.rn.f32 	%f39, %f37, 0f3B000000, %f38;
	ld.global.nc.f32 	%f40, [%rd4+96];
	add.f32 	%f13, %f40, %f39;
	// inline asm
	{  cvt.rn.f16.f32 %rs25, %f13;}

	// inline asm
	st.global.u16 	[%rd5+49152], %rs25;
	// inline asm
	{  cvt.rn.f16.f32 %rs26, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs27,%rs25,%rs26;
}
	// inline asm
	ld.global.nc.u16 	%rs32, [%rd6+49152];
	// inline asm
	{mul.f16 %rs30,%rs27,%rs32;
}
	// inline asm
	st.global.u16 	[%rd7+49152], %rs30;
	ld.global.nc.f32 	%f41, [%rd3+131072];
	ld.global.nc.f32 	%f42, [%rd2+128];
	mul.f32 	%f43, %f42, %f41;
	ld.global.nc.f32 	%f44, [%rd1+131072];
	fma.rn.f32 	%f45, %f43, 0f3B000000, %f44;
	ld.global.nc.f32 	%f46, [%rd4+128];
	add.f32 	%f15, %f46, %f45;
	// inline asm
	{  cvt.rn.f16.f32 %rs33, %f15;}

	// inline asm
	st.global.u16 	[%rd5+65536], %rs33;
	// inline asm
	{  cvt.rn.f16.f32 %rs34, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs35,%rs33,%rs34;
}
	// inline asm
	ld.global.nc.u16 	%rs40, [%rd6+65536];
	// inline asm
	{mul.f16 %rs38,%rs35,%rs40;
}
	// inline asm
	st.global.u16 	[%rd7+65536], %rs38;
	ld.global.nc.f32 	%f47, [%rd3+163840];
	ld.global.nc.f32 	%f48, [%rd2+160];
	mul.f32 	%f49, %f48, %f47;
	ld.global.nc.f32 	%f50, [%rd1+163840];
	fma.rn.f32 	%f51, %f49, 0f3B000000, %f50;
	ld.global.nc.f32 	%f52, [%rd4+160];
	add.f32 	%f17, %f52, %f51;
	// inline asm
	{  cvt.rn.f16.f32 %rs41, %f17;}

	// inline asm
	st.global.u16 	[%rd5+81920], %rs41;
	// inline asm
	{  cvt.rn.f16.f32 %rs42, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs43,%rs41,%rs42;
}
	// inline asm
	ld.global.nc.u16 	%rs48, [%rd6+81920];
	// inline asm
	{mul.f16 %rs46,%rs43,%rs48;
}
	// inline asm
	st.global.u16 	[%rd7+81920], %rs46;
	ld.global.nc.f32 	%f53, [%rd3+196608];
	ld.global.nc.f32 	%f54, [%rd2+192];
	mul.f32 	%f55, %f54, %f53;
	ld.global.nc.f32 	%f56, [%rd1+196608];
	fma.rn.f32 	%f57, %f55, 0f3B000000, %f56;
	ld.global.nc.f32 	%f58, [%rd4+192];
	add.f32 	%f19, %f58, %f57;
	// inline asm
	{  cvt.rn.f16.f32 %rs49, %f19;}

	// inline asm
	st.global.u16 	[%rd5+98304], %rs49;
	// inline asm
	{  cvt.rn.f16.f32 %rs50, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs51,%rs49,%rs50;
}
	// inline asm
	ld.global.nc.u16 	%rs56, [%rd6+98304];
	// inline asm
	{mul.f16 %rs54,%rs51,%rs56;
}
	// inline asm
	st.global.u16 	[%rd7+98304], %rs54;
	ld.global.nc.f32 	%f59, [%rd3+229376];
	ld.global.nc.f32 	%f60, [%rd2+224];
	mul.f32 	%f61, %f60, %f59;
	ld.global.nc.f32 	%f62, [%rd1+229376];
	fma.rn.f32 	%f63, %f61, 0f3B000000, %f62;
	ld.global.nc.f32 	%f64, [%rd4+224];
	add.f32 	%f21, %f64, %f63;
	// inline asm
	{  cvt.rn.f16.f32 %rs57, %f21;}

	// inline asm
	st.global.u16 	[%rd5+114688], %rs57;
	// inline asm
	{  cvt.rn.f16.f32 %rs58, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs59,%rs57,%rs58;
}
	// inline asm
	ld.global.nc.u16 	%rs64, [%rd6+114688];
	// inline asm
	{mul.f16 %rs62,%rs59,%rs64;
}
	// inline asm
	st.global.u16 	[%rd7+114688], %rs62;
	bar.sync 	0;
	ld.global.u16 	%rs65, [%rd7];
	// inline asm
	{  cvt.f32.f16 %f65, %rs65;}

	// inline asm
	add.f32 	%f73, %f65, 0f00000000;
	sub.f32 	%f74, %f73, %f65;
	ld.global.u16 	%rs66, [%rd7+16384];
	// inline asm
	{  cvt.f32.f16 %f66, %rs66;}

	// inline asm
	sub.f32 	%f75, %f66, %f74;
	add.f32 	%f76, %f73, %f75;
	sub.f32 	%f77, %f76, %f73;
	sub.f32 	%f78, %f77, %f75;
	ld.global.u16 	%rs67, [%rd7+32768];
	// inline asm
	{  cvt.f32.f16 %f67, %rs67;}

	// inline asm
	sub.f32 	%f79, %f67, %f78;
	add.f32 	%f80, %f76, %f79;
	sub.f32 	%f81, %f80, %f76;
	sub.f32 	%f82, %f81, %f79;
	ld.global.u16 	%rs68, [%rd7+49152];
	// inline asm
	{  cvt.f32.f16 %f68, %rs68;}

	// inline asm
	sub.f32 	%f83, %f68, %f82;
	add.f32 	%f84, %f80, %f83;
	sub.f32 	%f85, %f84, %f80;
	sub.f32 	%f86, %f85, %f83;
	ld.global.u16 	%rs69, [%rd7+65536];
	// inline asm
	{  cvt.f32.f16 %f69, %rs69;}

	// inline asm
	sub.f32 	%f87, %f69, %f86;
	add.f32 	%f88, %f84, %f87;
	sub.f32 	%f89, %f88, %f84;
	sub.f32 	%f90, %f89, %f87;
	ld.global.u16 	%rs70, [%rd7+81920];
	// inline asm
	{  cvt.f32.f16 %f70, %rs70;}

	// inline asm
	sub.f32 	%f91, %f70, %f90;
	add.f32 	%f92, %f88, %f91;
	sub.f32 	%f93, %f92, %f88;
	sub.f32 	%f94, %f93, %f91;
	ld.global.u16 	%rs71, [%rd7+98304];
	// inline asm
	{  cvt.f32.f16 %f71, %rs71;}

	// inline asm
	sub.f32 	%f95, %f71, %f94;
	add.f32 	%f96, %f92, %f95;
	sub.f32 	%f97, %f96, %f92;
	sub.f32 	%f98, %f97, %f95;
	ld.global.u16 	%rs72, [%rd7+114688];
	// inline asm
	{  cvt.f32.f16 %f72, %rs72;}

	// inline asm
	sub.f32 	%f99, %f72, %f98;
	add.f32 	%f100, %f96, %f99;
	mov.u32 	%r21, %ntid.x;
	mad.lo.s32 	%r5, %r21, %r1, %r3;
	and.b32  	%r6, %r5, 127;
	shr.u32 	%r7, %r5, 7;
	shl.b32 	%r22, %r7, 7;
	add.s32 	%r23, %r22, %r6;
	shl.b32 	%r24, %r23, 2;
	mov.u32 	%r25, _ZZ83Fused_Mul_Mul_Add_Add_Cast_Mul_Mul_Cast_ReduceSum_split_8117196722514213955_kernel0E8red_buf1;
	add.s32 	%r8, %r25, %r24;
	st.shared.f32 	[%r8], %f100;
	bar.sync 	0;
	setp.gt.u32	%p4, %r5, 511;
	@%p4 bra 	BB0_4;

	ld.shared.f32 	%f101, [%r8];
	ld.shared.f32 	%f102, [%r8+2048];
	add.f32 	%f103, %f101, %f102;
	st.shared.f32 	[%r8], %f103;

BB0_4:
	bar.sync 	0;
	setp.gt.u32	%p5, %r5, 255;
	@%p5 bra 	BB0_6;

	ld.shared.f32 	%f104, [%r8];
	ld.shared.f32 	%f105, [%r8+1024];
	add.f32 	%f106, %f104, %f105;
	st.shared.f32 	[%r8], %f106;

BB0_6:
	bar.sync 	0;
	setp.ne.s32	%p6, %r7, 0;
	@%p6 bra 	BB0_8;

	ld.shared.f32 	%f107, [%r8];
	ld.shared.f32 	%f108, [%r8+512];
	add.f32 	%f109, %f107, %f108;
	st.shared.f32 	[%r8], %f109;

BB0_8:
	setp.eq.s32	%p1, %r7, 0;
	bar.sync 	0;
	@!%p1 bra 	BB0_10;
	bra.uni 	BB0_9;

BB0_9:
	ld.shared.f32 	%f110, [%r4];
	shl.b32 	%r26, %r6, 2;
	add.s32 	%r28, %r25, %r26;
	ld.shared.f32 	%f111, [%r28];
	add.f32 	%f112, %f110, %f111;
	st.shared.f32 	[%r4], %f112;

BB0_10:
	setp.eq.s32	%p2, %r1, 0;
	bar.sync 	0;
	@!%p2 bra 	BB0_12;
	bra.uni 	BB0_11;

BB0_11:
	ld.shared.f32 	%f113, [%r4];
	add.s32 	%r29, %r2, %r3;
	cvta.to.global.u64 	%rd27, %rd9;
	mul.wide.s32 	%rd28, %r29, 4;
	add.s64 	%rd29, %rd27, %rd28;
	atom.global.add.f32 	%f114, [%rd29], %f113;

BB0_12:
	bar.sync 	0;
	ret;
}


