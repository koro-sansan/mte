//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0
// _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E39T_add_input_1_T_cast_input_0_red_shared has been demoted
// _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E8red_buf0 has been demoted

.visible .entry Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0(
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_0,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_1,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_2,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_3,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_4,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_5,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_6,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_7,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_8,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_9,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_10,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_11,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_12,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_13,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_14,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_15,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_16,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_17,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_18
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<12>;
	.reg .f32 	%f<157>;
	.reg .b32 	%r<157>;
	.reg .b64 	%rd<97>;
	// demoted variable
	.shared .align 4 .b8 _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E39T_add_input_1_T_cast_input_0_red_shared[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E8red_buf0[4096];

	ld.param.u64 	%rd22, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_0];
	ld.param.u64 	%rd23, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_1];
	ld.param.u64 	%rd24, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_2];
	ld.param.u64 	%rd25, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_4];
	ld.param.u64 	%rd26, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_5];
	ld.param.u64 	%rd27, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_6];
	ld.param.u64 	%rd28, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_7];
	ld.param.u64 	%rd29, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_10];
	ld.param.u64 	%rd30, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_11];
	ld.param.u64 	%rd31, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_12];
	ld.param.u64 	%rd32, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_13];
	ld.param.u64 	%rd33, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_14];
	ld.param.u64 	%rd34, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_15];
	ld.param.u64 	%rd35, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_16];
	ld.param.u64 	%rd36, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_17];
	ld.param.u64 	%rd37, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_18];
	cvta.to.global.u64 	%rd1, %rd37;
	cvta.to.global.u64 	%rd2, %rd31;
	cvta.to.global.u64 	%rd3, %rd29;
	cvta.to.global.u64 	%rd4, %rd35;
	cvta.to.global.u64 	%rd5, %rd36;
	cvta.to.global.u64 	%rd6, %rd34;
	cvta.to.global.u64 	%rd7, %rd22;
	cvta.to.global.u64 	%rd8, %rd30;
	cvta.to.global.u64 	%rd9, %rd23;
	cvta.to.global.u64 	%rd10, %rd24;
	cvta.to.global.u64 	%rd11, %rd33;
	cvta.to.global.u64 	%rd12, %rd26;
	cvta.to.global.u64 	%rd13, %rd25;
	cvta.to.global.u64 	%rd14, %rd32;
	cvta.to.global.u64 	%rd15, %rd28;
	cvta.to.global.u64 	%rd16, %rd27;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r35, %r1, 127;
	setp.gt.u32	%p2, %r35, 254;
	@%p2 bra 	BB0_2;

	shr.s32 	%r36, %r1, 31;
	shr.u32 	%r37, %r36, 25;
	add.s32 	%r38, %r1, %r37;
	and.b32  	%r39, %r38, 1073741696;
	sub.s32 	%r40, %r1, %r39;
	shl.b32 	%r41, %r40, 2;
	mov.u32 	%r42, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E39T_add_input_1_T_cast_input_0_red_shared;
	add.s32 	%r43, %r42, %r41;
	mov.u32 	%r44, 0;
	st.shared.u32 	[%r43], %r44;

BB0_2:
	bar.sync 	0;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r45, %r2, 3;
	mov.u32 	%r46, 1268;
	sub.s32 	%r47, %r46, %r45;
	mov.u32 	%r48, 7;
	min.s32 	%r3, %r48, %r47;
	shr.s32 	%r49, %r1, 31;
	shr.u32 	%r50, %r49, 25;
	add.s32 	%r51, %r1, %r50;
	and.b32  	%r52, %r51, -128;
	sub.s32 	%r153, %r1, %r52;
	mov.f32 	%f147, 0f00000000;
	setp.lt.s32	%p3, %r3, 0;
	@%p3 bra 	BB0_34;

	shl.b32 	%r5, %r2, 6;
	shl.b32 	%r6, %r2, 15;
	shr.s32 	%r7, %r51, 7;
	shl.b32 	%r8, %r7, 9;
	mov.u32 	%r60, %ctaid.y;
	shl.b32 	%r9, %r60, 7;
	add.s32 	%r10, %r3, 1;
	and.b32  	%r56, %r10, 3;
	mov.f32 	%f146, 0f00000000;
	mov.u32 	%r151, 0;
	setp.eq.s32	%p4, %r56, 0;
	@%p4 bra 	BB0_4;

	mov.u32 	%r150, 0;
	setp.eq.s32	%p5, %r56, 1;
	@%p5 bra 	BB0_6;
	bra.uni 	BB0_7;

BB0_6:
	mov.f32 	%f141, %f146;
	bra.uni 	BB0_16;

BB0_4:
	mov.f32 	%f147, %f146;
	bra.uni 	BB0_20;

BB0_7:
	mov.u32 	%r149, 0;
	setp.eq.s32	%p6, %r56, 2;
	@%p6 bra 	BB0_8;
	bra.uni 	BB0_9;

BB0_8:
	mov.f32 	%f137, %f146;
	bra.uni 	BB0_12;

BB0_9:
	add.s32 	%r62, %r5, %r7;
	mov.u32 	%r149, 1;
	setp.gt.s32	%p7, %r62, 10148;
	@%p7 bra 	BB0_10;

	add.s32 	%r64, %r6, %r8;
	add.s32 	%r65, %r64, %r9;
	add.s32 	%r66, %r65, %r153;
	mul.wide.s32 	%rd38, %r66, 4;
	add.s64 	%rd39, %rd16, %rd38;
	ld.global.nc.f32 	%f46, [%rd39];
	mul.wide.s32 	%rd40, %r66, 2;
	add.s64 	%rd41, %rd15, %rd40;
	ld.global.nc.u16 	%rs1, [%rd41];
	// inline asm
	{  cvt.f32.f16 %f45, %rs1;}

	// inline asm
	add.f32 	%f47, %f46, %f45;
	add.f32 	%f137, %f47, 0f00000000;
	sub.f32 	%f146, %f137, %f47;
	bra.uni 	BB0_12;

BB0_10:
	mov.f32 	%f137, %f146;

BB0_12:
	shl.b32 	%r67, %r149, 3;
	add.s32 	%r68, %r5, %r67;
	add.s32 	%r69, %r68, %r7;
	setp.gt.s32	%p8, %r69, 10148;
	@%p8 bra 	BB0_13;

	shl.b32 	%r70, %r149, 12;
	add.s32 	%r71, %r6, %r70;
	add.s32 	%r72, %r71, %r8;
	add.s32 	%r73, %r72, %r9;
	add.s32 	%r74, %r73, %r153;
	mul.wide.s32 	%rd42, %r74, 4;
	add.s64 	%rd43, %rd16, %rd42;
	ld.global.nc.f32 	%f49, [%rd43];
	mul.wide.s32 	%rd44, %r74, 2;
	add.s64 	%rd45, %rd15, %rd44;
	ld.global.nc.u16 	%rs2, [%rd45];
	// inline asm
	{  cvt.f32.f16 %f48, %rs2;}

	// inline asm
	add.f32 	%f50, %f49, %f48;
	sub.f32 	%f51, %f50, %f146;
	add.f32 	%f141, %f137, %f51;
	sub.f32 	%f52, %f141, %f137;
	sub.f32 	%f146, %f52, %f51;
	bra.uni 	BB0_15;

BB0_13:
	mov.f32 	%f141, %f137;

BB0_15:
	add.s32 	%r150, %r149, 1;

BB0_16:
	shl.b32 	%r75, %r150, 3;
	add.s32 	%r76, %r5, %r75;
	add.s32 	%r77, %r76, %r7;
	setp.gt.s32	%p9, %r77, 10148;
	@%p9 bra 	BB0_17;

	shl.b32 	%r78, %r150, 12;
	add.s32 	%r79, %r6, %r78;
	add.s32 	%r80, %r79, %r8;
	add.s32 	%r81, %r80, %r9;
	add.s32 	%r82, %r81, %r153;
	mul.wide.s32 	%rd46, %r82, 4;
	add.s64 	%rd47, %rd16, %rd46;
	ld.global.nc.f32 	%f54, [%rd47];
	mul.wide.s32 	%rd48, %r82, 2;
	add.s64 	%rd49, %rd15, %rd48;
	ld.global.nc.u16 	%rs3, [%rd49];
	// inline asm
	{  cvt.f32.f16 %f53, %rs3;}

	// inline asm
	add.f32 	%f55, %f54, %f53;
	sub.f32 	%f56, %f55, %f146;
	add.f32 	%f147, %f141, %f56;
	sub.f32 	%f57, %f147, %f141;
	sub.f32 	%f146, %f57, %f56;
	bra.uni 	BB0_19;

BB0_17:
	mov.f32 	%f147, %f141;

BB0_19:
	add.s32 	%r151, %r150, 1;

BB0_20:
	add.s32 	%r136, %r3, 1;
	setp.lt.u32	%p10, %r136, 4;
	@%p10 bra 	BB0_34;

BB0_21:
	shl.b32 	%r83, %r151, 3;
	add.s32 	%r84, %r5, %r83;
	add.s32 	%r85, %r84, %r7;
	shl.b32 	%r86, %r151, 12;
	add.s32 	%r87, %r6, %r86;
	add.s32 	%r88, %r87, %r8;
	add.s32 	%r89, %r88, %r9;
	add.s32 	%r90, %r89, %r153;
	mul.wide.s32 	%rd50, %r90, 4;
	add.s64 	%rd17, %rd16, %rd50;
	mul.wide.s32 	%rd51, %r90, 2;
	add.s64 	%rd18, %rd15, %rd51;
	setp.gt.s32	%p11, %r85, 10148;
	@%p11 bra 	BB0_22;

	ld.global.nc.f32 	%f59, [%rd17];
	ld.global.nc.u16 	%rs4, [%rd18];
	// inline asm
	{  cvt.f32.f16 %f58, %rs4;}

	// inline asm
	add.f32 	%f60, %f59, %f58;
	sub.f32 	%f61, %f60, %f146;
	add.f32 	%f148, %f147, %f61;
	sub.f32 	%f62, %f148, %f147;
	sub.f32 	%f146, %f62, %f61;
	bra.uni 	BB0_24;

BB0_22:
	mov.f32 	%f148, %f147;

BB0_24:
	add.s32 	%r92, %r83, %r5;
	add.s32 	%r93, %r92, %r7;
	add.s32 	%r94, %r93, 8;
	setp.gt.s32	%p12, %r94, 10148;
	@%p12 bra 	BB0_25;

	ld.global.nc.f32 	%f64, [%rd17+16384];
	ld.global.nc.u16 	%rs5, [%rd18+8192];
	// inline asm
	{  cvt.f32.f16 %f63, %rs5;}

	// inline asm
	add.f32 	%f65, %f64, %f63;
	sub.f32 	%f66, %f65, %f146;
	add.f32 	%f150, %f148, %f66;
	sub.f32 	%f67, %f150, %f148;
	sub.f32 	%f146, %f67, %f66;
	bra.uni 	BB0_27;

BB0_25:
	mov.f32 	%f150, %f148;

BB0_27:
	add.s32 	%r98, %r93, 16;
	setp.gt.s32	%p13, %r98, 10148;
	@%p13 bra 	BB0_28;

	ld.global.nc.f32 	%f69, [%rd17+32768];
	ld.global.nc.u16 	%rs6, [%rd18+16384];
	// inline asm
	{  cvt.f32.f16 %f68, %rs6;}

	// inline asm
	add.f32 	%f70, %f69, %f68;
	sub.f32 	%f71, %f70, %f146;
	add.f32 	%f152, %f150, %f71;
	sub.f32 	%f72, %f152, %f150;
	sub.f32 	%f146, %f72, %f71;
	bra.uni 	BB0_30;

BB0_28:
	mov.f32 	%f152, %f150;

BB0_30:
	add.s32 	%r17, %r151, 3;
	shl.b32 	%r99, %r17, 3;
	add.s32 	%r100, %r5, %r99;
	add.s32 	%r101, %r100, %r7;
	setp.gt.s32	%p14, %r101, 10148;
	@%p14 bra 	BB0_31;

	ld.global.nc.f32 	%f74, [%rd17+49152];
	ld.global.nc.u16 	%rs7, [%rd18+24576];
	// inline asm
	{  cvt.f32.f16 %f73, %rs7;}

	// inline asm
	add.f32 	%f75, %f74, %f73;
	sub.f32 	%f76, %f75, %f146;
	add.f32 	%f147, %f152, %f76;
	sub.f32 	%f77, %f147, %f152;
	sub.f32 	%f146, %f77, %f76;
	bra.uni 	BB0_33;

BB0_31:
	mov.f32 	%f147, %f152;

BB0_33:
	add.s32 	%r151, %r151, 4;
	setp.lt.s32	%p15, %r17, %r3;
	@%p15 bra 	BB0_21;

BB0_34:
	mov.u32 	%r145, %tid.x;
	mov.u32 	%r106, %tid.y;
	mov.u32 	%r107, %ntid.x;
	mad.lo.s32 	%r20, %r106, %r107, %r145;
	and.b32  	%r21, %r20, 127;
	shr.u32 	%r22, %r20, 7;
	shl.b32 	%r108, %r22, 7;
	add.s32 	%r109, %r108, %r21;
	shl.b32 	%r110, %r109, 2;
	mov.u32 	%r111, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E8red_buf0;
	add.s32 	%r23, %r111, %r110;
	st.shared.f32 	[%r23], %f147;
	bar.sync 	0;
	setp.gt.u32	%p16, %r20, 511;
	@%p16 bra 	BB0_36;

	ld.shared.f32 	%f78, [%r23];
	ld.shared.f32 	%f79, [%r23+2048];
	add.f32 	%f80, %f78, %f79;
	st.shared.f32 	[%r23], %f80;

BB0_36:
	bar.sync 	0;
	setp.gt.u32	%p17, %r20, 255;
	@%p17 bra 	BB0_38;

	ld.shared.f32 	%f81, [%r23];
	ld.shared.f32 	%f82, [%r23+1024];
	add.f32 	%f83, %f81, %f82;
	st.shared.f32 	[%r23], %f83;

BB0_38:
	bar.sync 	0;
	setp.ne.s32	%p18, %r22, 0;
	@%p18 bra 	BB0_40;

	ld.shared.f32 	%f84, [%r23];
	ld.shared.f32 	%f85, [%r23+512];
	add.f32 	%f86, %f84, %f85;
	st.shared.f32 	[%r23], %f86;

BB0_40:
	setp.eq.s32	%p1, %r22, 0;
	bar.sync 	0;
	@!%p1 bra 	BB0_42;
	bra.uni 	BB0_41;

BB0_41:
	shl.b32 	%r112, %r153, 2;
	mov.u32 	%r113, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E39T_add_input_1_T_cast_input_0_red_shared;
	add.s32 	%r114, %r113, %r112;
	ld.shared.f32 	%f87, [%r114];
	shl.b32 	%r115, %r21, 2;
	add.s32 	%r117, %r111, %r115;
	ld.shared.f32 	%f88, [%r117];
	add.f32 	%f89, %f87, %f88;
	st.shared.f32 	[%r114], %f89;

BB0_42:
	bar.sync 	0;
	mov.u32 	%r146, %tid.x;
	setp.gt.s32	%p19, %r146, 127;
	@%p19 bra 	BB0_44;

	mov.u32 	%r148, %tid.x;
	ld.param.u64 	%rd96, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_8];
	shl.b32 	%r118, %r148, 2;
	mov.u32 	%r119, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0E39T_add_input_1_T_cast_input_0_red_shared;
	add.s32 	%r120, %r119, %r118;
	ld.shared.f32 	%f90, [%r120];
	mov.u32 	%r121, %ctaid.y;
	shl.b32 	%r122, %r121, 7;
	add.s32 	%r123, %r122, %r148;
	cvta.to.global.u64 	%rd52, %rd96;
	mul.wide.s32 	%rd53, %r123, 4;
	add.s64 	%rd54, %rd52, %rd53;
	atom.global.add.f32 	%f91, [%rd54], %f90;

BB0_44:
	bar.sync 	0;
	mov.u32 	%r147, %tid.x;
	mov.u32 	%r137, %ctaid.x;
	setp.lt.s32	%p20, %r147, 512;
	setp.lt.s32	%p21, %r137, 128;
	and.pred  	%p22, %p21, %p20;
	@!%p22 bra 	BB0_53;
	bra.uni 	BB0_45;

BB0_45:
	mov.u32 	%r142, %tid.x;
	ld.param.u64 	%rd95, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_5803979727076238320_kernel0_param_3];
	shr.s32 	%r141, %r142, 31;
	shr.u32 	%r140, %r141, 25;
	add.s32 	%r139, %r142, %r140;
	mov.u32 	%r138, %ctaid.x;
	mov.u32 	%r125, %ctaid.y;
	shr.s32 	%r129, %r139, 7;
	shl.b32 	%r130, %r138, 2;
	add.s32 	%r131, %r129, %r130;
	cvta.to.global.u64 	%rd55, %rd95;
	mul.wide.s32 	%rd56, %r131, 4;
	add.s64 	%rd19, %rd55, %rd56;
	mad.lo.s32 	%r132, %r125, 1299456, %r129;
	mad.lo.s32 	%r133, %r153, 512, %r132;
	mad.lo.s32 	%r155, %r138, 4, %r133;
	mad.lo.s32 	%r154, %r125, 2538, %r153;
	mov.u32 	%r156, -20;

BB0_46:
	setp.gt.s32	%p23, %r153, 2537;
	@%p23 bra 	BB0_49;

	setp.gt.s32	%p24, %r154, 10148;
	@%p24 bra 	BB0_49;

	mul.wide.s32 	%rd57, %r155, 4;
	add.s64 	%rd58, %rd16, %rd57;
	ld.global.nc.f32 	%f94, [%rd58];
	mul.wide.s32 	%rd59, %r155, 2;
	add.s64 	%rd60, %rd15, %rd59;
	ld.global.nc.u16 	%rs8, [%rd60];
	// inline asm
	{  cvt.f32.f16 %f92, %rs8;}

	// inline asm
	add.f32 	%f95, %f94, %f92;
	ld.global.nc.f32 	%f96, [%rd19];
	mul.f32 	%f97, %f95, %f96;
	add.s64 	%rd61, %rd14, %rd57;
	st.global.f32 	[%rd61], %f97;
	add.s64 	%rd62, %rd13, %rd57;
	mul.wide.s32 	%rd63, %r154, 4;
	add.s64 	%rd64, %rd12, %rd63;
	ld.global.nc.f32 	%f98, [%rd64];
	ld.global.nc.f32 	%f99, [%rd62];
	sub.f32 	%f100, %f99, %f98;
	add.s64 	%rd65, %rd11, %rd57;
	st.global.f32 	[%rd65], %f100;
	add.s64 	%rd66, %rd10, %rd57;
	add.s64 	%rd67, %rd9, %rd63;
	ld.global.nc.f32 	%f101, [%rd67];
	mul.f32 	%f102, %f100, %f101;
	ld.global.nc.f32 	%f103, [%rd66];
	mul.f32 	%f104, %f103, %f102;
	add.s64 	%rd68, %rd8, %rd57;
	st.global.f32 	[%rd68], %f104;
	add.s64 	%rd69, %rd7, %rd63;
	ld.global.nc.f32 	%f105, [%rd69];
	mul.f32 	%f106, %f97, %f105;
	add.s64 	%rd70, %rd6, %rd57;
	st.global.f32 	[%rd70], %f106;
	mul.f32 	%f107, %f103, %f96;
	add.s64 	%rd71, %rd5, %rd57;
	st.global.f32 	[%rd71], %f107;
	mul.f32 	%f108, %f107, %f100;
	add.s64 	%rd72, %rd4, %rd57;
	st.global.f32 	[%rd72], %f108;
	// inline asm
	{  cvt.f32.f16 %f93, %rs8;}

	// inline asm
	add.f32 	%f109, %f94, %f93;
	mul.f32 	%f110, %f105, %f100;
	mul.f32 	%f111, %f109, %f110;
	add.s64 	%rd73, %rd3, %rd57;
	st.global.f32 	[%rd73], %f111;
	mul.f32 	%f112, %f97, %f100;
	add.s64 	%rd74, %rd2, %rd57;
	st.global.f32 	[%rd74], %f112;
	mul.f32 	%f113, %f107, %f101;
	add.s64 	%rd75, %rd1, %rd57;
	st.global.f32 	[%rd75], %f113;

BB0_49:
	add.s32 	%r134, %r153, 128;
	setp.gt.s32	%p25, %r134, 2537;
	@%p25 bra 	BB0_52;

	add.s32 	%r30, %r154, 128;
	setp.gt.s32	%p26, %r30, 10148;
	@%p26 bra 	BB0_52;

	add.s32 	%r135, %r155, 65536;
	mul.wide.s32 	%rd76, %r135, 4;
	add.s64 	%rd77, %rd16, %rd76;
	ld.global.nc.f32 	%f116, [%rd77];
	mul.wide.s32 	%rd78, %r135, 2;
	add.s64 	%rd79, %rd15, %rd78;
	ld.global.nc.u16 	%rs10, [%rd79];
	// inline asm
	{  cvt.f32.f16 %f114, %rs10;}

	// inline asm
	add.f32 	%f117, %f116, %f114;
	ld.global.nc.f32 	%f118, [%rd19];
	mul.f32 	%f119, %f117, %f118;
	add.s64 	%rd80, %rd14, %rd76;
	st.global.f32 	[%rd80], %f119;
	add.s64 	%rd81, %rd13, %rd76;
	mul.wide.s32 	%rd82, %r30, 4;
	add.s64 	%rd83, %rd12, %rd82;
	ld.global.nc.f32 	%f120, [%rd83];
	ld.global.nc.f32 	%f121, [%rd81];
	sub.f32 	%f122, %f121, %f120;
	add.s64 	%rd84, %rd11, %rd76;
	st.global.f32 	[%rd84], %f122;
	add.s64 	%rd85, %rd10, %rd76;
	add.s64 	%rd86, %rd9, %rd82;
	ld.global.nc.f32 	%f123, [%rd86];
	mul.f32 	%f124, %f122, %f123;
	ld.global.nc.f32 	%f125, [%rd85];
	mul.f32 	%f126, %f125, %f124;
	add.s64 	%rd87, %rd8, %rd76;
	st.global.f32 	[%rd87], %f126;
	add.s64 	%rd88, %rd7, %rd82;
	ld.global.nc.f32 	%f127, [%rd88];
	mul.f32 	%f128, %f119, %f127;
	add.s64 	%rd89, %rd6, %rd76;
	st.global.f32 	[%rd89], %f128;
	mul.f32 	%f129, %f125, %f118;
	add.s64 	%rd90, %rd5, %rd76;
	st.global.f32 	[%rd90], %f129;
	mul.f32 	%f130, %f129, %f122;
	add.s64 	%rd91, %rd4, %rd76;
	st.global.f32 	[%rd91], %f130;
	// inline asm
	{  cvt.f32.f16 %f115, %rs10;}

	// inline asm
	add.f32 	%f131, %f116, %f115;
	mul.f32 	%f132, %f127, %f122;
	mul.f32 	%f133, %f131, %f132;
	add.s64 	%rd92, %rd3, %rd76;
	st.global.f32 	[%rd92], %f133;
	mul.f32 	%f134, %f119, %f122;
	add.s64 	%rd93, %rd2, %rd76;
	st.global.f32 	[%rd93], %f134;
	mul.f32 	%f135, %f129, %f123;
	add.s64 	%rd94, %rd1, %rd76;
	st.global.f32 	[%rd94], %f135;

BB0_52:
	add.s32 	%r156, %r156, 2;
	add.s32 	%r155, %r155, 131072;
	add.s32 	%r154, %r154, 256;
	add.s32 	%r153, %r153, 256;
	setp.ne.s32	%p27, %r156, 0;
	@%p27 bra 	BB0_46;

BB0_53:
	ret;
}


