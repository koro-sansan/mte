//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0
// _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E39T_add_input_1_T_cast_input_0_red_shared has been demoted
// _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E8red_buf0 has been demoted

.visible .entry Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0(
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_0,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_1,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_2,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_3,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_4,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_5,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_6,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_7,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_8,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_9,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_10,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_11,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_12,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_13,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_14,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_15,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_16,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_17,
	.param .u64 Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_18
)
{
	.reg .pred 	%p<21>;
	.reg .b16 	%rs<11>;
	.reg .f32 	%f<121>;
	.reg .b32 	%r<75>;
	.reg .b64 	%rd<64>;
	// demoted variable
	.shared .align 4 .b8 _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E39T_add_input_1_T_cast_input_0_red_shared[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E8red_buf0[4096];

	ld.param.u64 	%rd20, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_0];
	ld.param.u64 	%rd21, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_1];
	ld.param.u64 	%rd22, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_2];
	ld.param.u64 	%rd23, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_3];
	ld.param.u64 	%rd24, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_4];
	ld.param.u64 	%rd25, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_5];
	ld.param.u64 	%rd36, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_6];
	ld.param.u64 	%rd37, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_7];
	ld.param.u64 	%rd26, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_8];
	ld.param.u64 	%rd27, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_10];
	ld.param.u64 	%rd28, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_11];
	ld.param.u64 	%rd29, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_12];
	ld.param.u64 	%rd30, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_13];
	ld.param.u64 	%rd31, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_14];
	ld.param.u64 	%rd32, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_15];
	ld.param.u64 	%rd33, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_16];
	ld.param.u64 	%rd34, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_17];
	ld.param.u64 	%rd35, [Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0_param_18];
	cvta.to.global.u64 	%rd1, %rd37;
	cvta.to.global.u64 	%rd2, %rd36;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r21, %r1, 127;
	setp.gt.u32	%p3, %r21, 254;
	@%p3 bra 	BB0_2;

	shr.s32 	%r22, %r1, 31;
	shr.u32 	%r23, %r22, 25;
	add.s32 	%r24, %r1, %r23;
	and.b32  	%r25, %r24, 1073741696;
	sub.s32 	%r26, %r1, %r25;
	shl.b32 	%r27, %r26, 2;
	mov.u32 	%r28, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E39T_add_input_1_T_cast_input_0_red_shared;
	add.s32 	%r29, %r28, %r27;
	mov.u32 	%r30, 0;
	st.shared.u32 	[%r29], %r30;

BB0_2:
	shr.s32 	%r31, %r1, 31;
	shr.u32 	%r32, %r31, 25;
	add.s32 	%r33, %r1, %r32;
	and.b32  	%r34, %r33, -128;
	sub.s32 	%r71, %r1, %r34;
	bar.sync 	0;
	mov.u32 	%r3, %ctaid.x;
	shl.b32 	%r35, %r3, 6;
	shl.b32 	%r36, %r3, 15;
	shr.s32 	%r40, %r33, 7;
	shl.b32 	%r41, %r40, 9;
	mov.u32 	%r4, %ctaid.y;
	shl.b32 	%r5, %r4, 7;
	add.s32 	%r6, %r35, %r40;
	add.s32 	%r42, %r36, %r41;
	add.s32 	%r43, %r42, %r5;
	add.s32 	%r44, %r43, %r71;
	mul.wide.s32 	%rd38, %r44, 4;
	add.s64 	%rd3, %rd2, %rd38;
	mul.wide.s32 	%rd39, %r44, 2;
	add.s64 	%rd4, %rd1, %rd39;
	mov.f32 	%f106, 0f00000000;
	setp.gt.s32	%p4, %r6, 41278;
	mov.f32 	%f109, %f106;
	@%p4 bra 	BB0_4;

	ld.global.nc.f32 	%f34, [%rd3];
	ld.global.nc.u16 	%rs1, [%rd4];
	// inline asm
	{  cvt.f32.f16 %f33, %rs1;}

	// inline asm
	add.f32 	%f35, %f34, %f33;
	add.f32 	%f106, %f35, 0f00000000;
	sub.f32 	%f109, %f106, %f35;

BB0_4:
	add.s32 	%r45, %r6, 8;
	setp.gt.s32	%p5, %r45, 41278;
	@%p5 bra 	BB0_5;

	ld.global.nc.f32 	%f37, [%rd3+16384];
	ld.global.nc.u16 	%rs2, [%rd4+8192];
	// inline asm
	{  cvt.f32.f16 %f36, %rs2;}

	// inline asm
	add.f32 	%f38, %f37, %f36;
	sub.f32 	%f39, %f38, %f109;
	add.f32 	%f108, %f106, %f39;
	sub.f32 	%f40, %f108, %f106;
	sub.f32 	%f109, %f40, %f39;
	bra.uni 	BB0_7;

BB0_5:
	mov.f32 	%f108, %f106;

BB0_7:
	add.s32 	%r46, %r6, 16;
	setp.gt.s32	%p6, %r46, 41278;
	@%p6 bra 	BB0_8;

	ld.global.nc.f32 	%f42, [%rd3+32768];
	ld.global.nc.u16 	%rs3, [%rd4+16384];
	// inline asm
	{  cvt.f32.f16 %f41, %rs3;}

	// inline asm
	add.f32 	%f43, %f42, %f41;
	sub.f32 	%f44, %f43, %f109;
	add.f32 	%f110, %f108, %f44;
	sub.f32 	%f45, %f110, %f108;
	sub.f32 	%f109, %f45, %f44;
	bra.uni 	BB0_10;

BB0_8:
	mov.f32 	%f110, %f108;

BB0_10:
	add.s32 	%r47, %r6, 24;
	setp.gt.s32	%p7, %r47, 41278;
	@%p7 bra 	BB0_11;

	ld.global.nc.f32 	%f47, [%rd3+49152];
	ld.global.nc.u16 	%rs4, [%rd4+24576];
	// inline asm
	{  cvt.f32.f16 %f46, %rs4;}

	// inline asm
	add.f32 	%f48, %f47, %f46;
	sub.f32 	%f49, %f48, %f109;
	add.f32 	%f112, %f110, %f49;
	sub.f32 	%f50, %f112, %f110;
	sub.f32 	%f109, %f50, %f49;
	bra.uni 	BB0_13;

BB0_11:
	mov.f32 	%f112, %f110;

BB0_13:
	add.s32 	%r48, %r6, 32;
	setp.gt.s32	%p8, %r48, 41278;
	@%p8 bra 	BB0_14;

	ld.global.nc.f32 	%f52, [%rd3+65536];
	ld.global.nc.u16 	%rs5, [%rd4+32768];
	// inline asm
	{  cvt.f32.f16 %f51, %rs5;}

	// inline asm
	add.f32 	%f53, %f52, %f51;
	sub.f32 	%f54, %f53, %f109;
	add.f32 	%f114, %f112, %f54;
	sub.f32 	%f55, %f114, %f112;
	sub.f32 	%f109, %f55, %f54;
	bra.uni 	BB0_16;

BB0_14:
	mov.f32 	%f114, %f112;

BB0_16:
	add.s32 	%r49, %r6, 40;
	setp.gt.s32	%p9, %r49, 41278;
	@%p9 bra 	BB0_17;

	ld.global.nc.f32 	%f57, [%rd3+81920];
	ld.global.nc.u16 	%rs6, [%rd4+40960];
	// inline asm
	{  cvt.f32.f16 %f56, %rs6;}

	// inline asm
	add.f32 	%f58, %f57, %f56;
	sub.f32 	%f59, %f58, %f109;
	add.f32 	%f116, %f114, %f59;
	sub.f32 	%f60, %f116, %f114;
	sub.f32 	%f109, %f60, %f59;
	bra.uni 	BB0_19;

BB0_17:
	mov.f32 	%f116, %f114;

BB0_19:
	add.s32 	%r50, %r6, 48;
	setp.gt.s32	%p10, %r50, 41278;
	@%p10 bra 	BB0_20;

	ld.global.nc.f32 	%f62, [%rd3+98304];
	ld.global.nc.u16 	%rs7, [%rd4+49152];
	// inline asm
	{  cvt.f32.f16 %f61, %rs7;}

	// inline asm
	add.f32 	%f63, %f62, %f61;
	sub.f32 	%f64, %f63, %f109;
	add.f32 	%f118, %f116, %f64;
	sub.f32 	%f65, %f118, %f116;
	sub.f32 	%f109, %f65, %f64;
	bra.uni 	BB0_22;

BB0_20:
	mov.f32 	%f118, %f116;

BB0_22:
	add.s32 	%r51, %r6, 56;
	setp.gt.s32	%p11, %r51, 41278;
	@%p11 bra 	BB0_24;

	ld.global.nc.f32 	%f67, [%rd3+114688];
	ld.global.nc.u16 	%rs8, [%rd4+57344];
	// inline asm
	{  cvt.f32.f16 %f66, %rs8;}

	// inline asm
	add.f32 	%f68, %f67, %f66;
	sub.f32 	%f69, %f68, %f109;
	add.f32 	%f118, %f118, %f69;

BB0_24:
	mov.u32 	%r52, %tid.y;
	mov.u32 	%r53, %ntid.x;
	mad.lo.s32 	%r7, %r52, %r53, %r1;
	and.b32  	%r8, %r7, 127;
	shr.u32 	%r9, %r7, 7;
	shl.b32 	%r54, %r9, 7;
	add.s32 	%r55, %r54, %r8;
	shl.b32 	%r56, %r55, 2;
	mov.u32 	%r57, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E8red_buf0;
	add.s32 	%r10, %r57, %r56;
	st.shared.f32 	[%r10], %f118;
	bar.sync 	0;
	setp.gt.u32	%p12, %r7, 511;
	@%p12 bra 	BB0_26;

	ld.shared.f32 	%f70, [%r10];
	ld.shared.f32 	%f71, [%r10+2048];
	add.f32 	%f72, %f70, %f71;
	st.shared.f32 	[%r10], %f72;

BB0_26:
	bar.sync 	0;
	setp.gt.u32	%p13, %r7, 255;
	@%p13 bra 	BB0_28;

	ld.shared.f32 	%f73, [%r10];
	ld.shared.f32 	%f74, [%r10+1024];
	add.f32 	%f75, %f73, %f74;
	st.shared.f32 	[%r10], %f75;

BB0_28:
	bar.sync 	0;
	setp.ne.s32	%p14, %r9, 0;
	@%p14 bra 	BB0_30;

	ld.shared.f32 	%f76, [%r10];
	ld.shared.f32 	%f77, [%r10+512];
	add.f32 	%f78, %f76, %f77;
	st.shared.f32 	[%r10], %f78;

BB0_30:
	setp.eq.s32	%p1, %r9, 0;
	bar.sync 	0;
	@!%p1 bra 	BB0_32;
	bra.uni 	BB0_31;

BB0_31:
	shl.b32 	%r58, %r71, 2;
	mov.u32 	%r59, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E39T_add_input_1_T_cast_input_0_red_shared;
	add.s32 	%r60, %r59, %r58;
	ld.shared.f32 	%f79, [%r60];
	shl.b32 	%r61, %r8, 2;
	add.s32 	%r63, %r57, %r61;
	ld.shared.f32 	%f80, [%r63];
	add.f32 	%f81, %f79, %f80;
	st.shared.f32 	[%r60], %f81;

BB0_32:
	bar.sync 	0;
	setp.gt.s32	%p15, %r1, 127;
	@%p15 bra 	BB0_34;

	shl.b32 	%r64, %r1, 2;
	mov.u32 	%r65, _ZZ102Fused_Cast_Add_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_Mul_split_1185085230323336226_kernel0E39T_add_input_1_T_cast_input_0_red_shared;
	add.s32 	%r66, %r65, %r64;
	ld.shared.f32 	%f82, [%r66];
	add.s32 	%r67, %r5, %r1;
	cvta.to.global.u64 	%rd40, %rd26;
	mul.wide.s32 	%rd41, %r67, 4;
	add.s64 	%rd42, %rd40, %rd41;
	atom.global.add.f32 	%f83, [%rd42], %f82;

BB0_34:
	setp.lt.u32	%p2, %r21, 255;
	bar.sync 	0;
	setp.lt.s32	%p16, %r3, 512;
	and.pred  	%p17, %p16, %p2;
	@!%p17 bra 	BB0_40;
	bra.uni 	BB0_35;

BB0_35:
	cvta.to.global.u64 	%rd43, %rd23;
	mul.wide.s32 	%rd44, %r3, 4;
	add.s64 	%rd5, %rd43, %rd44;
	mad.lo.s32 	%r70, %r4, 5283840, %r3;
	mad.lo.s32 	%r74, %r71, 512, %r70;
	mad.lo.s32 	%r72, %r4, 10320, %r71;
	cvta.to.global.u64 	%rd6, %rd30;
	cvta.to.global.u64 	%rd7, %rd24;
	cvta.to.global.u64 	%rd8, %rd25;
	cvta.to.global.u64 	%rd9, %rd31;
	cvta.to.global.u64 	%rd10, %rd22;
	cvta.to.global.u64 	%rd11, %rd21;
	cvta.to.global.u64 	%rd12, %rd28;
	cvta.to.global.u64 	%rd13, %rd20;
	cvta.to.global.u64 	%rd14, %rd32;
	cvta.to.global.u64 	%rd15, %rd34;
	cvta.to.global.u64 	%rd16, %rd33;
	cvta.to.global.u64 	%rd17, %rd27;
	cvta.to.global.u64 	%rd18, %rd29;
	cvta.to.global.u64 	%rd19, %rd35;
	mov.u32 	%r73, -81;

BB0_36:
	setp.gt.s32	%p18, %r71, 10319;
	@%p18 bra 	BB0_39;

	setp.gt.s32	%p19, %r72, 41278;
	@%p19 bra 	BB0_39;

	mul.wide.s32 	%rd45, %r74, 4;
	add.s64 	%rd46, %rd2, %rd45;
	ld.global.nc.f32 	%f86, [%rd46];
	mul.wide.s32 	%rd47, %r74, 2;
	add.s64 	%rd48, %rd1, %rd47;
	ld.global.nc.u16 	%rs9, [%rd48];
	// inline asm
	{  cvt.f32.f16 %f84, %rs9;}

	// inline asm
	add.f32 	%f87, %f86, %f84;
	ld.global.nc.f32 	%f88, [%rd5];
	mul.f32 	%f89, %f87, %f88;
	add.s64 	%rd49, %rd6, %rd45;
	st.global.f32 	[%rd49], %f89;
	add.s64 	%rd50, %rd7, %rd45;
	mul.wide.s32 	%rd51, %r72, 4;
	add.s64 	%rd52, %rd8, %rd51;
	ld.global.nc.f32 	%f90, [%rd52];
	ld.global.nc.f32 	%f91, [%rd50];
	sub.f32 	%f92, %f91, %f90;
	add.s64 	%rd53, %rd9, %rd45;
	st.global.f32 	[%rd53], %f92;
	add.s64 	%rd54, %rd10, %rd45;
	add.s64 	%rd55, %rd11, %rd51;
	ld.global.nc.f32 	%f93, [%rd55];
	mul.f32 	%f94, %f92, %f93;
	ld.global.nc.f32 	%f95, [%rd54];
	mul.f32 	%f96, %f95, %f94;
	add.s64 	%rd56, %rd12, %rd45;
	st.global.f32 	[%rd56], %f96;
	add.s64 	%rd57, %rd13, %rd51;
	ld.global.nc.f32 	%f97, [%rd57];
	mul.f32 	%f98, %f89, %f97;
	add.s64 	%rd58, %rd14, %rd45;
	st.global.f32 	[%rd58], %f98;
	mul.f32 	%f99, %f95, %f88;
	add.s64 	%rd59, %rd15, %rd45;
	st.global.f32 	[%rd59], %f99;
	mul.f32 	%f100, %f99, %f92;
	add.s64 	%rd60, %rd16, %rd45;
	st.global.f32 	[%rd60], %f100;
	// inline asm
	{  cvt.f32.f16 %f85, %rs9;}

	// inline asm
	add.f32 	%f101, %f86, %f85;
	mul.f32 	%f102, %f97, %f92;
	mul.f32 	%f103, %f101, %f102;
	add.s64 	%rd61, %rd17, %rd45;
	st.global.f32 	[%rd61], %f103;
	mul.f32 	%f104, %f89, %f92;
	add.s64 	%rd62, %rd18, %rd45;
	st.global.f32 	[%rd62], %f104;
	mul.f32 	%f105, %f99, %f93;
	add.s64 	%rd63, %rd19, %rd45;
	st.global.f32 	[%rd63], %f105;

BB0_39:
	add.s32 	%r74, %r74, 65536;
	add.s32 	%r72, %r72, 128;
	add.s32 	%r71, %r71, 128;
	add.s32 	%r73, %r73, 1;
	setp.ne.s32	%p20, %r73, 0;
	@%p20 bra 	BB0_36;

BB0_40:
	ret;
}


