//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0
// _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared has been demoted
// _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E8red_buf0 has been demoted

.visible .entry Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0(
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_0,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_1,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_2,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_3,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_4,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_5,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_6,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_7,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_8,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_9,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_10,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_11,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_12,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_13
)
{
	.reg .pred 	%p<12>;
	.reg .b16 	%rs<113>;
	.reg .f32 	%f<97>;
	.reg .b32 	%r<105>;
	.reg .b64 	%rd<65>;
	// demoted variable
	.shared .align 4 .b8 _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E8red_buf0[4096];

	ld.param.u64 	%rd15, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_0];
	ld.param.u64 	%rd16, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_2];
	ld.param.u64 	%rd17, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_3];
	ld.param.u64 	%rd18, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_4];
	ld.param.u64 	%rd19, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_5];
	ld.param.u64 	%rd20, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_6];
	ld.param.u64 	%rd21, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_9];
	ld.param.u64 	%rd22, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_10];
	ld.param.u64 	%rd23, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_11];
	ld.param.u64 	%rd24, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_12];
	ld.param.u64 	%rd25, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_13];
	cvta.to.global.u64 	%rd1, %rd25;
	cvta.to.global.u64 	%rd2, %rd21;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd22;
	cvta.to.global.u64 	%rd5, %rd24;
	cvta.to.global.u64 	%rd6, %rd17;
	cvta.to.global.u64 	%rd7, %rd16;
	cvta.to.global.u64 	%rd8, %rd23;
	cvta.to.global.u64 	%rd9, %rd18;
	cvta.to.global.u64 	%rd10, %rd20;
	cvta.to.global.u64 	%rd11, %rd19;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r28, %r1, 127;
	shr.s32 	%r29, %r1, 31;
	shr.u32 	%r30, %r29, 25;
	add.s32 	%r31, %r1, %r30;
	and.b32  	%r32, %r31, 1073741696;
	sub.s32 	%r33, %r1, %r32;
	shl.b32 	%r34, %r33, 2;
	mov.u32 	%r35, _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared;
	add.s32 	%r2, %r35, %r34;
	setp.gt.u32	%p2, %r28, 254;
	@%p2 bra 	BB0_2;

	mov.u32 	%r36, 0;
	st.shared.u32 	[%r2], %r36;

BB0_2:
	and.b32  	%r40, %r31, -128;
	sub.s32 	%r3, %r1, %r40;
	bar.sync 	0;
	mov.u32 	%r4, %ctaid.x;
	shl.b32 	%r41, %r4, 15;
	shr.s32 	%r5, %r31, 7;
	shl.b32 	%r45, %r5, 9;
	mov.u32 	%r6, %ctaid.y;
	shl.b32 	%r7, %r6, 7;
	add.s32 	%r46, %r3, %r41;
	add.s32 	%r47, %r46, %r45;
	add.s32 	%r48, %r47, %r7;
	mul.wide.s32 	%rd26, %r48, 2;
	add.s64 	%rd27, %rd11, %rd26;
	ld.global.nc.u16 	%rs2, [%rd27];
	add.s64 	%rd28, %rd10, %rd26;
	ld.global.nc.u16 	%rs3, [%rd28];
	// inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// inline asm
	add.s64 	%rd29, %rd9, %rd26;
	ld.global.nc.u16 	%rs6, [%rd29];
	// inline asm
	{add.f16 %rs4,%rs1,%rs6;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f3, %rs4;}

	// inline asm
	add.f32 	%f11, %f3, 0f00000000;
	sub.f32 	%f12, %f11, %f3;
	ld.global.nc.u16 	%rs9, [%rd27+8192];
	ld.global.nc.u16 	%rs10, [%rd28+8192];
	// inline asm
	{add.f16 %rs8,%rs9,%rs10;
}
	// inline asm
	ld.global.nc.u16 	%rs13, [%rd29+8192];
	// inline asm
	{add.f16 %rs11,%rs8,%rs13;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f4, %rs11;}

	// inline asm
	sub.f32 	%f13, %f4, %f12;
	add.f32 	%f14, %f11, %f13;
	sub.f32 	%f15, %f14, %f11;
	sub.f32 	%f16, %f15, %f13;
	ld.global.nc.u16 	%rs16, [%rd27+16384];
	ld.global.nc.u16 	%rs17, [%rd28+16384];
	// inline asm
	{add.f16 %rs15,%rs16,%rs17;
}
	// inline asm
	ld.global.nc.u16 	%rs20, [%rd29+16384];
	// inline asm
	{add.f16 %rs18,%rs15,%rs20;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f5, %rs18;}

	// inline asm
	sub.f32 	%f17, %f5, %f16;
	add.f32 	%f18, %f14, %f17;
	sub.f32 	%f19, %f18, %f14;
	sub.f32 	%f20, %f19, %f17;
	ld.global.nc.u16 	%rs23, [%rd27+24576];
	ld.global.nc.u16 	%rs24, [%rd28+24576];
	// inline asm
	{add.f16 %rs22,%rs23,%rs24;
}
	// inline asm
	ld.global.nc.u16 	%rs27, [%rd29+24576];
	// inline asm
	{add.f16 %rs25,%rs22,%rs27;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f6, %rs25;}

	// inline asm
	sub.f32 	%f21, %f6, %f20;
	add.f32 	%f22, %f18, %f21;
	sub.f32 	%f23, %f22, %f18;
	sub.f32 	%f24, %f23, %f21;
	ld.global.nc.u16 	%rs30, [%rd27+32768];
	ld.global.nc.u16 	%rs31, [%rd28+32768];
	// inline asm
	{add.f16 %rs29,%rs30,%rs31;
}
	// inline asm
	ld.global.nc.u16 	%rs34, [%rd29+32768];
	// inline asm
	{add.f16 %rs32,%rs29,%rs34;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f7, %rs32;}

	// inline asm
	sub.f32 	%f25, %f7, %f24;
	add.f32 	%f26, %f22, %f25;
	sub.f32 	%f27, %f26, %f22;
	sub.f32 	%f28, %f27, %f25;
	ld.global.nc.u16 	%rs37, [%rd27+40960];
	ld.global.nc.u16 	%rs38, [%rd28+40960];
	// inline asm
	{add.f16 %rs36,%rs37,%rs38;
}
	// inline asm
	ld.global.nc.u16 	%rs41, [%rd29+40960];
	// inline asm
	{add.f16 %rs39,%rs36,%rs41;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f8, %rs39;}

	// inline asm
	sub.f32 	%f29, %f8, %f28;
	add.f32 	%f30, %f26, %f29;
	sub.f32 	%f31, %f30, %f26;
	sub.f32 	%f32, %f31, %f29;
	ld.global.nc.u16 	%rs44, [%rd27+49152];
	ld.global.nc.u16 	%rs45, [%rd28+49152];
	// inline asm
	{add.f16 %rs43,%rs44,%rs45;
}
	// inline asm
	ld.global.nc.u16 	%rs48, [%rd29+49152];
	// inline asm
	{add.f16 %rs46,%rs43,%rs48;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f9, %rs46;}

	// inline asm
	sub.f32 	%f33, %f9, %f32;
	add.f32 	%f34, %f30, %f33;
	sub.f32 	%f35, %f34, %f30;
	sub.f32 	%f36, %f35, %f33;
	ld.global.nc.u16 	%rs51, [%rd27+57344];
	ld.global.nc.u16 	%rs52, [%rd28+57344];
	// inline asm
	{add.f16 %rs50,%rs51,%rs52;
}
	// inline asm
	ld.global.nc.u16 	%rs55, [%rd29+57344];
	// inline asm
	{add.f16 %rs53,%rs50,%rs55;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f10, %rs53;}

	// inline asm
	sub.f32 	%f37, %f10, %f36;
	add.f32 	%f38, %f34, %f37;
	mov.u32 	%r49, %tid.y;
	mov.u32 	%r50, %ntid.x;
	mad.lo.s32 	%r8, %r49, %r50, %r1;
	and.b32  	%r9, %r8, 127;
	shr.u32 	%r10, %r8, 7;
	shl.b32 	%r51, %r10, 7;
	add.s32 	%r52, %r51, %r9;
	shl.b32 	%r53, %r52, 2;
	mov.u32 	%r54, _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E8red_buf0;
	add.s32 	%r11, %r54, %r53;
	st.shared.f32 	[%r11], %f38;
	bar.sync 	0;
	setp.gt.u32	%p3, %r8, 511;
	@%p3 bra 	BB0_4;

	ld.shared.f32 	%f39, [%r11];
	ld.shared.f32 	%f40, [%r11+2048];
	add.f32 	%f41, %f39, %f40;
	st.shared.f32 	[%r11], %f41;

BB0_4:
	bar.sync 	0;
	setp.gt.u32	%p4, %r8, 255;
	@%p4 bra 	BB0_6;

	ld.shared.f32 	%f42, [%r11];
	ld.shared.f32 	%f43, [%r11+1024];
	add.f32 	%f44, %f42, %f43;
	st.shared.f32 	[%r11], %f44;

BB0_6:
	bar.sync 	0;
	setp.ne.s32	%p5, %r10, 0;
	@%p5 bra 	BB0_8;

	ld.shared.f32 	%f45, [%r11];
	ld.shared.f32 	%f46, [%r11+512];
	add.f32 	%f47, %f45, %f46;
	st.shared.f32 	[%r11], %f47;

BB0_8:
	setp.eq.s32	%p1, %r10, 0;
	bar.sync 	0;
	@!%p1 bra 	BB0_10;
	bra.uni 	BB0_9;

BB0_9:
	mov.u32 	%r98, _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E8red_buf0;
	mov.u32 	%r97, %tid.x;
	mov.u32 	%r96, %ntid.x;
	mov.u32 	%r95, %tid.y;
	mad.lo.s32 	%r94, %r95, %r96, %r97;
	and.b32  	%r93, %r94, 127;
	ld.shared.f32 	%f48, [%r2];
	shl.b32 	%r55, %r93, 2;
	add.s32 	%r57, %r98, %r55;
	ld.shared.f32 	%f49, [%r57];
	add.f32 	%f50, %f48, %f49;
	st.shared.f32 	[%r2], %f50;

BB0_10:
	bar.sync 	0;
	mov.u32 	%r72, %tid.x;
	setp.gt.s32	%p6, %r72, 127;
	@%p6 bra 	BB0_12;

	ld.param.u64 	%rd64, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_7];
	mov.u32 	%r92, %ctaid.y;
	shl.b32 	%r91, %r92, 7;
	mov.u32 	%r90, _ZZ86Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared;
	mov.u32 	%r89, %tid.x;
	shl.b32 	%r58, %r89, 2;
	add.s32 	%r60, %r90, %r58;
	ld.shared.f32 	%f51, [%r60];
	add.s32 	%r61, %r91, %r89;
	cvta.to.global.u64 	%rd30, %rd64;
	mul.wide.s32 	%rd31, %r61, 4;
	add.s64 	%rd32, %rd30, %rd31;
	atom.global.add.f32 	%f52, [%rd32], %f51;

BB0_12:
	bar.sync 	0;
	setp.gt.s32	%p7, %r3, 3;
	@%p7 bra 	BB0_19;

	ld.param.u64 	%rd63, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_3555633042689687601_kernel0_param_1];
	mov.u32 	%r73, %ctaid.x;
	shl.b32 	%r62, %r73, 2;
	add.s32 	%r63, %r3, %r62;
	cvta.to.global.u64 	%rd33, %rd63;
	mul.wide.s32 	%rd34, %r63, 4;
	add.s64 	%rd12, %rd33, %rd34;
	setp.gt.s32	%p8, %r73, 127;
	@%p8 bra 	BB0_16;

	mov.u32 	%r88, %tid.x;
	shr.s32 	%r87, %r88, 31;
	shr.u32 	%r86, %r87, 25;
	add.s32 	%r85, %r88, %r86;
	shr.s32 	%r84, %r85, 7;
	mov.u32 	%r83, %ctaid.y;
	mov.u32 	%r82, %ctaid.x;
	ld.global.nc.f32 	%f1, [%rd12];
	mad.lo.s32 	%r100, %r83, 1536, %r84;
	mad.lo.s32 	%r65, %r83, 786432, %r3;
	mad.lo.s32 	%r66, %r84, 512, %r65;
	mad.lo.s32 	%r99, %r82, 4, %r66;
	mov.u32 	%r101, -192;

BB0_15:
	mul.wide.s32 	%rd35, %r99, 2;
	add.s64 	%rd36, %rd11, %rd35;
	ld.global.nc.u16 	%rs58, [%rd36];
	add.s64 	%rd37, %rd10, %rd35;
	ld.global.nc.u16 	%rs59, [%rd37];
	// inline asm
	{add.f16 %rs57,%rs58,%rs59;
}
	// inline asm
	add.s64 	%rd38, %rd9, %rd35;
	ld.global.nc.u16 	%rs62, [%rd38];
	// inline asm
	{add.f16 %rs60,%rs57,%rs62;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f53, %rs60;}

	// inline asm
	mul.f32 	%f57, %f53, %f1;
	mul.wide.s32 	%rd39, %r99, 4;
	add.s64 	%rd40, %rd8, %rd39;
	st.global.f32 	[%rd40], %f57;
	add.s64 	%rd41, %rd7, %rd39;
	mul.wide.s32 	%rd42, %r100, 4;
	add.s64 	%rd43, %rd6, %rd42;
	ld.global.nc.f32 	%f58, [%rd43];
	ld.global.nc.f32 	%f59, [%rd41];
	sub.f32 	%f60, %f59, %f58;
	add.s64 	%rd44, %rd5, %rd39;
	st.global.f32 	[%rd44], %f60;
	mul.f32 	%f61, %f57, %f60;
	add.s64 	%rd45, %rd4, %rd39;
	st.global.f32 	[%rd45], %f61;
	// inline asm
	{add.f16 %rs64,%rs58,%rs59;
}
	// inline asm
	// inline asm
	{add.f16 %rs67,%rs64,%rs62;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f54, %rs67;}

	// inline asm
	add.s64 	%rd46, %rd3, %rd42;
	ld.global.nc.f32 	%f62, [%rd46];
	mul.f32 	%f63, %f62, %f60;
	mul.f32 	%f64, %f54, %f63;
	add.s64 	%rd47, %rd2, %rd39;
	st.global.f32 	[%rd47], %f64;
	mul.f32 	%f65, %f57, %f62;
	add.s64 	%rd48, %rd1, %rd39;
	st.global.f32 	[%rd48], %f65;
	ld.global.nc.u16 	%rs72, [%rd36+8192];
	ld.global.nc.u16 	%rs73, [%rd37+8192];
	// inline asm
	{add.f16 %rs71,%rs72,%rs73;
}
	// inline asm
	ld.global.nc.u16 	%rs76, [%rd38+8192];
	// inline asm
	{add.f16 %rs74,%rs71,%rs76;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f55, %rs74;}

	// inline asm
	mul.f32 	%f66, %f55, %f1;
	st.global.f32 	[%rd40+16384], %f66;
	ld.global.nc.f32 	%f67, [%rd43+32];
	ld.global.nc.f32 	%f68, [%rd41+16384];
	sub.f32 	%f69, %f68, %f67;
	st.global.f32 	[%rd44+16384], %f69;
	mul.f32 	%f70, %f66, %f69;
	st.global.f32 	[%rd45+16384], %f70;
	// inline asm
	{add.f16 %rs78,%rs72,%rs73;
}
	// inline asm
	// inline asm
	{add.f16 %rs81,%rs78,%rs76;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f56, %rs81;}

	// inline asm
	ld.global.nc.f32 	%f71, [%rd46+32];
	mul.f32 	%f72, %f71, %f69;
	mul.f32 	%f73, %f56, %f72;
	st.global.f32 	[%rd47+16384], %f73;
	mul.f32 	%f74, %f66, %f71;
	st.global.f32 	[%rd48+16384], %f74;
	add.s32 	%r100, %r100, 16;
	add.s32 	%r99, %r99, 8192;
	add.s32 	%r101, %r101, 2;
	setp.ne.s32	%p9, %r101, 0;
	@%p9 bra 	BB0_15;

BB0_16:
	mov.u32 	%r74, %ctaid.x;
	add.s32 	%r67, %r74, 96;
	setp.gt.s32	%p10, %r67, 127;
	@%p10 bra 	BB0_19;

	mov.u32 	%r81, %tid.x;
	shr.s32 	%r80, %r81, 31;
	shr.u32 	%r79, %r80, 25;
	add.s32 	%r78, %r81, %r79;
	shr.s32 	%r77, %r78, 7;
	mov.u32 	%r76, %ctaid.y;
	mov.u32 	%r75, %ctaid.x;
	ld.global.nc.f32 	%f2, [%rd12+1536];
	mad.lo.s32 	%r103, %r76, 1536, %r77;
	mad.lo.s32 	%r69, %r76, 786432, %r3;
	mad.lo.s32 	%r70, %r77, 512, %r69;
	mad.lo.s32 	%r102, %r75, 4, %r70;
	mov.u32 	%r104, -192;

BB0_18:
	add.s32 	%r71, %r102, 384;
	mul.wide.s32 	%rd49, %r71, 2;
	add.s64 	%rd50, %rd11, %rd49;
	ld.global.nc.u16 	%rs86, [%rd50];
	add.s64 	%rd51, %rd10, %rd49;
	ld.global.nc.u16 	%rs87, [%rd51];
	// inline asm
	{add.f16 %rs85,%rs86,%rs87;
}
	// inline asm
	add.s64 	%rd52, %rd9, %rd49;
	ld.global.nc.u16 	%rs90, [%rd52];
	// inline asm
	{add.f16 %rs88,%rs85,%rs90;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f75, %rs88;}

	// inline asm
	mul.f32 	%f79, %f75, %f2;
	mul.wide.s32 	%rd53, %r71, 4;
	add.s64 	%rd54, %rd8, %rd53;
	st.global.f32 	[%rd54], %f79;
	add.s64 	%rd55, %rd7, %rd53;
	mul.wide.s32 	%rd56, %r103, 4;
	add.s64 	%rd57, %rd6, %rd56;
	ld.global.nc.f32 	%f80, [%rd57];
	ld.global.nc.f32 	%f81, [%rd55];
	sub.f32 	%f82, %f81, %f80;
	add.s64 	%rd58, %rd5, %rd53;
	st.global.f32 	[%rd58], %f82;
	mul.f32 	%f83, %f79, %f82;
	add.s64 	%rd59, %rd4, %rd53;
	st.global.f32 	[%rd59], %f83;
	// inline asm
	{add.f16 %rs92,%rs86,%rs87;
}
	// inline asm
	// inline asm
	{add.f16 %rs95,%rs92,%rs90;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f76, %rs95;}

	// inline asm
	add.s64 	%rd60, %rd3, %rd56;
	ld.global.nc.f32 	%f84, [%rd60];
	mul.f32 	%f85, %f84, %f82;
	mul.f32 	%f86, %f76, %f85;
	add.s64 	%rd61, %rd2, %rd53;
	st.global.f32 	[%rd61], %f86;
	mul.f32 	%f87, %f79, %f84;
	add.s64 	%rd62, %rd1, %rd53;
	st.global.f32 	[%rd62], %f87;
	ld.global.nc.u16 	%rs100, [%rd50+8192];
	ld.global.nc.u16 	%rs101, [%rd51+8192];
	// inline asm
	{add.f16 %rs99,%rs100,%rs101;
}
	// inline asm
	ld.global.nc.u16 	%rs104, [%rd52+8192];
	// inline asm
	{add.f16 %rs102,%rs99,%rs104;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f77, %rs102;}

	// inline asm
	mul.f32 	%f88, %f77, %f2;
	st.global.f32 	[%rd54+16384], %f88;
	ld.global.nc.f32 	%f89, [%rd57+32];
	ld.global.nc.f32 	%f90, [%rd55+16384];
	sub.f32 	%f91, %f90, %f89;
	st.global.f32 	[%rd58+16384], %f91;
	mul.f32 	%f92, %f88, %f91;
	st.global.f32 	[%rd59+16384], %f92;
	// inline asm
	{add.f16 %rs106,%rs100,%rs101;
}
	// inline asm
	// inline asm
	{add.f16 %rs109,%rs106,%rs104;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f78, %rs109;}

	// inline asm
	ld.global.nc.f32 	%f93, [%rd60+32];
	mul.f32 	%f94, %f93, %f91;
	mul.f32 	%f95, %f78, %f94;
	st.global.f32 	[%rd61+16384], %f95;
	mul.f32 	%f96, %f88, %f93;
	st.global.f32 	[%rd62+16384], %f96;
	add.s32 	%r103, %r103, 16;
	add.s32 	%r102, %r102, 8192;
	add.s32 	%r104, %r104, 2;
	setp.ne.s32	%p11, %r104, 0;
	@%p11 bra 	BB0_18;

BB0_19:
	ret;
}


