//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0
// _ZZ60Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0E50T_cast_T_add_input_2_T_multiply_input_0_red_shared has been demoted
// _ZZ60Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0E8red_buf2 has been demoted

.visible .entry Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0(
	.param .u64 Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_0,
	.param .u64 Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_1,
	.param .u64 Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_2,
	.param .u64 Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_3
)
{
	.reg .pred 	%p<43>;
	.reg .b16 	%rs<65>;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<123>;
	.reg .b64 	%rd<35>;
	// demoted variable
	.shared .align 4 .b8 _ZZ60Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0E50T_cast_T_add_input_2_T_multiply_input_0_red_shared[256];
	// demoted variable
	.shared .align 4 .b8 _ZZ60Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0E8red_buf2[2048];

	ld.param.u64 	%rd11, [Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_0];
	ld.param.u64 	%rd9, [Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_1];
	ld.param.u64 	%rd12, [Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_2];
	ld.param.u64 	%rd10, [Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0_param_3];
	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd2, %rd12;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.y;
	shl.b32 	%r3, %r2, 6;
	mov.u32 	%r4, %tid.y;
	shl.b32 	%r20, %r4, 2;
	mov.u32 	%r21, _ZZ60Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0E50T_cast_T_add_input_2_T_multiply_input_0_red_shared;
	add.s32 	%r121, %r21, %r20;
	setp.ne.s32	%p6, %r1, 0;
	@%p6 bra 	BB0_2;

	mov.u32 	%r22, -8388611;
	st.shared.u32 	[%r121], %r22;

BB0_2:
	add.s32 	%r6, %r4, %r3;
	shl.b32 	%r23, %r6, 3;
	and.b32  	%r24, %r23, -4096;
	shl.b32 	%r25, %r4, 6;
	add.s32 	%r7, %r1, %r25;
	add.s32 	%r26, %r7, %r24;
	shl.b32 	%r27, %r2, 12;
	add.s32 	%r28, %r7, %r27;
	mov.f32 	%f3, 0f3E000000;
	// inline asm
	{  cvt.rn.f16.f32 %rs1, %f3;}

	// inline asm
	cvta.to.global.u64 	%rd13, %rd9;
	mul.wide.s32 	%rd14, %r28, 2;
	add.s64 	%rd3, %rd13, %rd14;
	ld.global.nc.u16 	%rs3, [%rd3];
	// inline asm
	{mul.f16 %rs2,%rs3,%rs1;
}
	// inline asm
	mul.wide.s32 	%rd15, %r26, 2;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.nc.u16 	%rs6, [%rd16];
	// inline asm
	{add.f16 %rs5,%rs6,%rs2;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f4, %rs5;}

	// inline asm
	mul.wide.s32 	%rd17, %r28, 4;
	add.s64 	%rd4, %rd2, %rd17;
	st.global.f32 	[%rd4], %f4;
	@%p6 bra 	BB0_4;

	mov.u32 	%r29, -8388611;
	st.shared.u32 	[%r121+32], %r29;

BB0_4:
	add.s32 	%r30, %r6, 8;
	shl.b32 	%r31, %r30, 3;
	and.b32  	%r32, %r31, -4096;
	add.s32 	%r33, %r7, %r32;
	add.s32 	%r34, %r33, 512;
	// inline asm
	{  cvt.rn.f16.f32 %rs9, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs11, [%rd3+1024];
	// inline asm
	{mul.f16 %rs10,%rs11,%rs9;
}
	// inline asm
	mul.wide.s32 	%rd18, %r34, 2;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.nc.u16 	%rs14, [%rd19];
	// inline asm
	{add.f16 %rs13,%rs14,%rs10;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f6, %rs13;}

	// inline asm
	st.global.f32 	[%rd4+2048], %f6;
	@%p6 bra 	BB0_6;

	mov.u32 	%r35, -8388611;
	st.shared.u32 	[%r121+64], %r35;

BB0_6:
	add.s32 	%r36, %r6, 16;
	shl.b32 	%r37, %r36, 3;
	and.b32  	%r38, %r37, -4096;
	add.s32 	%r39, %r7, %r38;
	add.s32 	%r40, %r39, 1024;
	// inline asm
	{  cvt.rn.f16.f32 %rs17, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs19, [%rd3+2048];
	// inline asm
	{mul.f16 %rs18,%rs19,%rs17;
}
	// inline asm
	mul.wide.s32 	%rd20, %r40, 2;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.nc.u16 	%rs22, [%rd21];
	// inline asm
	{add.f16 %rs21,%rs22,%rs18;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f8, %rs21;}

	// inline asm
	st.global.f32 	[%rd4+4096], %f8;
	@%p6 bra 	BB0_8;

	mov.u32 	%r41, -8388611;
	st.shared.u32 	[%r121+96], %r41;

BB0_8:
	add.s32 	%r42, %r6, 24;
	shl.b32 	%r43, %r42, 3;
	and.b32  	%r44, %r43, -4096;
	add.s32 	%r45, %r7, %r44;
	add.s32 	%r46, %r45, 1536;
	// inline asm
	{  cvt.rn.f16.f32 %rs25, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs27, [%rd3+3072];
	// inline asm
	{mul.f16 %rs26,%rs27,%rs25;
}
	// inline asm
	mul.wide.s32 	%rd22, %r46, 2;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.nc.u16 	%rs30, [%rd23];
	// inline asm
	{add.f16 %rs29,%rs30,%rs26;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f10, %rs29;}

	// inline asm
	st.global.f32 	[%rd4+6144], %f10;
	@%p6 bra 	BB0_10;

	mov.u32 	%r47, -8388611;
	st.shared.u32 	[%r121+128], %r47;

BB0_10:
	add.s32 	%r48, %r6, 32;
	shl.b32 	%r49, %r48, 3;
	and.b32  	%r50, %r49, -4096;
	add.s32 	%r51, %r7, %r50;
	add.s32 	%r52, %r51, 2048;
	// inline asm
	{  cvt.rn.f16.f32 %rs33, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs35, [%rd3+4096];
	// inline asm
	{mul.f16 %rs34,%rs35,%rs33;
}
	// inline asm
	mul.wide.s32 	%rd24, %r52, 2;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.nc.u16 	%rs38, [%rd25];
	// inline asm
	{add.f16 %rs37,%rs38,%rs34;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f12, %rs37;}

	// inline asm
	st.global.f32 	[%rd4+8192], %f12;
	@%p6 bra 	BB0_12;

	mov.u32 	%r53, -8388611;
	st.shared.u32 	[%r121+160], %r53;

BB0_12:
	add.s32 	%r54, %r6, 40;
	shl.b32 	%r55, %r54, 3;
	and.b32  	%r56, %r55, -4096;
	add.s32 	%r57, %r7, %r56;
	add.s32 	%r58, %r57, 2560;
	// inline asm
	{  cvt.rn.f16.f32 %rs41, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs43, [%rd3+5120];
	// inline asm
	{mul.f16 %rs42,%rs43,%rs41;
}
	// inline asm
	mul.wide.s32 	%rd26, %r58, 2;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.nc.u16 	%rs46, [%rd27];
	// inline asm
	{add.f16 %rs45,%rs46,%rs42;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f14, %rs45;}

	// inline asm
	st.global.f32 	[%rd4+10240], %f14;
	@%p6 bra 	BB0_14;

	mov.u32 	%r59, -8388611;
	st.shared.u32 	[%r121+192], %r59;

BB0_14:
	add.s32 	%r60, %r6, 48;
	shl.b32 	%r61, %r60, 3;
	and.b32  	%r62, %r61, -4096;
	add.s32 	%r63, %r7, %r62;
	add.s32 	%r64, %r63, 3072;
	// inline asm
	{  cvt.rn.f16.f32 %rs49, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs51, [%rd3+6144];
	// inline asm
	{mul.f16 %rs50,%rs51,%rs49;
}
	// inline asm
	mul.wide.s32 	%rd28, %r64, 2;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.nc.u16 	%rs54, [%rd29];
	// inline asm
	{add.f16 %rs53,%rs54,%rs50;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f16, %rs53;}

	// inline asm
	st.global.f32 	[%rd4+12288], %f16;
	@%p6 bra 	BB0_16;

	mov.u32 	%r65, -8388611;
	st.shared.u32 	[%r121+224], %r65;

BB0_16:
	add.s32 	%r66, %r6, 56;
	shl.b32 	%r67, %r66, 3;
	and.b32  	%r68, %r67, -4096;
	add.s32 	%r69, %r7, %r68;
	add.s32 	%r70, %r69, 3584;
	// inline asm
	{  cvt.rn.f16.f32 %rs57, %f3;}

	// inline asm
	ld.global.nc.u16 	%rs59, [%rd3+7168];
	// inline asm
	{mul.f16 %rs58,%rs59,%rs57;
}
	// inline asm
	mul.wide.s32 	%rd30, %r70, 2;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.nc.u16 	%rs62, [%rd31];
	// inline asm
	{add.f16 %rs61,%rs62,%rs58;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f18, %rs61;}

	// inline asm
	st.global.f32 	[%rd4+14336], %f18;
	cvta.to.global.u64 	%rd7, %rd10;
	bar.sync 	0;
	mov.u32 	%r72, %ntid.x;
	mad.lo.s32 	%r73, %r72, %r4, %r1;
	and.b32  	%r8, %r73, 63;
	and.b32  	%r74, %r73, 1073741760;
	add.s32 	%r75, %r74, %r8;
	shl.b32 	%r76, %r75, 2;
	mov.u32 	%r77, _ZZ60Fused_Mul_Add_Cast_ReduceMax_split_75729165100108020_kernel0E8red_buf2;
	add.s32 	%r9, %r77, %r76;
	shl.b32 	%r78, %r73, 2;
	and.b32  	%r79, %r78, -256;
	add.s32 	%r10, %r77, %r79;
	mad.lo.s32 	%r120, %r2, 4096, %r7;
	mov.u32 	%r122, -8;

BB0_17:
	mul.wide.s32 	%rd32, %r120, 4;
	add.s64 	%rd8, %rd2, %rd32;
	ld.global.f32 	%f19, [%rd8];
	mov.f32 	%f20, 0fFF7FFFFD;
	max.f32 	%f21, %f20, %f19;
	st.shared.f32 	[%r9], %f21;
	bar.sync 	0;
	setp.gt.u32	%p14, %r8, 31;
	@%p14 bra 	BB0_19;

	ld.shared.f32 	%f22, [%r9];
	ld.shared.f32 	%f23, [%r9+128];
	setp.gt.f32	%p15, %f23, %f22;
	selp.f32	%f24, %f23, %f22, %p15;
	st.shared.f32 	[%r9], %f24;

BB0_19:
	setp.lt.u32	%p1, %r8, 32;
	bar.sync 	0;
	@!%p1 bra 	BB0_22;
	bra.uni 	BB0_20;

BB0_20:
	ld.shared.f32 	%f25, [%r9];
	mov.b32 	 %r82, %f25;
	mov.u32 	%r83, 2;
	mov.u32 	%r84, 31;
	mov.u32 	%r85, 16;
	mov.u32 	%r86, -1;
	shfl.sync.down.b32 	%r87|%p16, %r82, %r85, %r84, %r86;
	mov.b32 	 %f26, %r87;
	setp.gt.f32	%p17, %f26, %f25;
	selp.f32	%f27, %f26, %f25, %p17;
	mov.b32 	 %r88, %f27;
	mov.u32 	%r89, 8;
	shfl.sync.down.b32 	%r90|%p18, %r88, %r89, %r84, %r86;
	mov.b32 	 %f28, %r90;
	setp.gt.f32	%p19, %f28, %f27;
	selp.f32	%f29, %f28, %f27, %p19;
	mov.b32 	 %r91, %f29;
	mov.u32 	%r92, 4;
	shfl.sync.down.b32 	%r93|%p20, %r91, %r92, %r84, %r86;
	mov.b32 	 %f30, %r93;
	setp.gt.f32	%p21, %f30, %f29;
	selp.f32	%f31, %f30, %f29, %p21;
	mov.b32 	 %r94, %f31;
	shfl.sync.down.b32 	%r95|%p22, %r94, %r83, %r84, %r86;
	mov.b32 	 %f32, %r95;
	setp.gt.f32	%p23, %f32, %f31;
	selp.f32	%f33, %f32, %f31, %p23;
	mov.b32 	 %r96, %f33;
	mov.u32 	%r97, 1;
	shfl.sync.down.b32 	%r98|%p24, %r96, %r97, %r84, %r86;
	mov.b32 	 %f34, %r98;
	setp.gt.f32	%p25, %f34, %f33;
	selp.f32	%f1, %f34, %f33, %p25;
	setp.ne.s32	%p26, %r8, 0;
	@%p26 bra 	BB0_22;

	st.shared.f32 	[%r9], %f1;

BB0_22:
	setp.eq.s32	%p2, %r8, 0;
	bar.sync 	0;
	@!%p2 bra 	BB0_24;
	bra.uni 	BB0_23;

BB0_23:
	ld.shared.f32 	%f35, [%r10];
	ld.shared.f32 	%f36, [%r121];
	setp.gt.f32	%p27, %f35, %f36;
	selp.f32	%f37, %f35, %f36, %p27;
	st.shared.f32 	[%r121], %f37;

BB0_24:
	ld.global.f32 	%f38, [%rd8+2048];
	max.f32 	%f40, %f20, %f38;
	st.shared.f32 	[%r9], %f40;
	bar.sync 	0;
	@!%p1 bra 	BB0_26;
	bra.uni 	BB0_25;

BB0_25:
	ld.shared.f32 	%f41, [%r9];
	ld.shared.f32 	%f42, [%r9+128];
	setp.gt.f32	%p28, %f42, %f41;
	selp.f32	%f43, %f42, %f41, %p28;
	st.shared.f32 	[%r9], %f43;

BB0_26:
	bar.sync 	0;
	@!%p1 bra 	BB0_29;
	bra.uni 	BB0_27;

BB0_27:
	ld.shared.f32 	%f44, [%r9];
	mov.b32 	 %r99, %f44;
	mov.u32 	%r100, 2;
	mov.u32 	%r101, 31;
	mov.u32 	%r102, 16;
	mov.u32 	%r103, -1;
	shfl.sync.down.b32 	%r104|%p29, %r99, %r102, %r101, %r103;
	mov.b32 	 %f45, %r104;
	setp.gt.f32	%p30, %f45, %f44;
	selp.f32	%f46, %f45, %f44, %p30;
	mov.b32 	 %r105, %f46;
	mov.u32 	%r106, 8;
	shfl.sync.down.b32 	%r107|%p31, %r105, %r106, %r101, %r103;
	mov.b32 	 %f47, %r107;
	setp.gt.f32	%p32, %f47, %f46;
	selp.f32	%f48, %f47, %f46, %p32;
	mov.b32 	 %r108, %f48;
	mov.u32 	%r109, 4;
	shfl.sync.down.b32 	%r110|%p33, %r108, %r109, %r101, %r103;
	mov.b32 	 %f49, %r110;
	setp.gt.f32	%p34, %f49, %f48;
	selp.f32	%f50, %f49, %f48, %p34;
	mov.b32 	 %r111, %f50;
	shfl.sync.down.b32 	%r112|%p35, %r111, %r100, %r101, %r103;
	mov.b32 	 %f51, %r112;
	setp.gt.f32	%p36, %f51, %f50;
	selp.f32	%f52, %f51, %f50, %p36;
	mov.b32 	 %r113, %f52;
	mov.u32 	%r114, 1;
	shfl.sync.down.b32 	%r115|%p37, %r113, %r114, %r101, %r103;
	mov.b32 	 %f53, %r115;
	setp.gt.f32	%p38, %f53, %f52;
	selp.f32	%f2, %f53, %f52, %p38;
	setp.ne.s32	%p39, %r8, 0;
	@%p39 bra 	BB0_29;

	st.shared.f32 	[%r9], %f2;

BB0_29:
	bar.sync 	0;
	@!%p2 bra 	BB0_31;
	bra.uni 	BB0_30;

BB0_30:
	ld.shared.f32 	%f54, [%r10];
	ld.shared.f32 	%f55, [%r121+32];
	setp.gt.f32	%p40, %f54, %f55;
	selp.f32	%f56, %f54, %f55, %p40;
	st.shared.f32 	[%r121+32], %f56;

BB0_31:
	add.s32 	%r122, %r122, 2;
	add.s32 	%r121, %r121, 64;
	add.s32 	%r120, %r120, 1024;
	setp.ne.s32	%p41, %r122, 0;
	@%p41 bra 	BB0_17;

	bar.sync 	0;
	setp.ne.s32	%p42, %r4, 0;
	@%p42 bra 	BB0_34;

	shl.b32 	%r116, %r1, 2;
	add.s32 	%r118, %r21, %r116;
	ld.shared.f32 	%f57, [%r118];
	add.s32 	%r119, %r3, %r1;
	mul.wide.s32 	%rd33, %r119, 4;
	add.s64 	%rd34, %rd7, %rd33;
	st.global.f32 	[%rd34], %f57;

BB0_34:
	bar.sync 	0;
	ret;
}


