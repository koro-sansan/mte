//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0
// _ZZ88Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0E136T_cast_T_multiply_T_multiply_T_add_T_cast_T_add_T_add_input_4_T_multiply_T_multiply_input_0_input_1_input_7_input_10_input_14_red_shared has been demoted
// _ZZ88Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0E8red_buf0 has been demoted

.visible .entry Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0(
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_0,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_1,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_2,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_3,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_4,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_5,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_6,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_7,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_8,
	.param .u64 Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_9
)
{
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<31>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<41>;
	.reg .b64 	%rd<34>;
	// demoted variable
	.shared .align 4 .b8 _ZZ88Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0E136T_cast_T_multiply_T_multiply_T_add_T_cast_T_add_T_add_input_4_T_multiply_T_multiply_input_0_input_1_input_7_input_10_input_14_red_shared[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ88Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0E8red_buf0[4096];

	ld.param.u64 	%rd18, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_0];
	ld.param.u64 	%rd19, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_1];
	ld.param.u64 	%rd20, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_2];
	ld.param.u64 	%rd21, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_3];
	ld.param.u64 	%rd22, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_4];
	ld.param.u64 	%rd23, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_5];
	ld.param.u64 	%rd17, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_6];
	ld.param.u64 	%rd24, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_8];
	ld.param.u64 	%rd25, [Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0_param_9];
	cvta.to.global.u64 	%rd1, %rd23;
	cvta.to.global.u64 	%rd2, %rd24;
	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvta.to.global.u64 	%rd6, %rd18;
	cvta.to.global.u64 	%rd7, %rd20;
	cvta.to.global.u64 	%rd8, %rd25;
	mov.u32 	%r1, %tid.y;
	shl.b32 	%r2, %r1, 9;
	mov.u32 	%r20, %ctaid.y;
	shl.b32 	%r3, %r20, 7;
	mov.u32 	%r4, %tid.x;
	shl.b32 	%r21, %r4, 2;
	mov.u32 	%r22, _ZZ88Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0E136T_cast_T_multiply_T_multiply_T_add_T_cast_T_add_T_add_input_4_T_multiply_T_multiply_input_0_input_1_input_7_input_10_input_14_red_shared;
	add.s32 	%r5, %r22, %r21;
	mov.u32 	%r23, %ctaid.x;
	mad.lo.s32 	%r39, %r23, 64, %r1;
	mad.lo.s32 	%r7, %r23, 32768, %r4;
	mad.lo.s32 	%r24, %r1, 512, %r7;
	mad.lo.s32 	%r38, %r20, 128, %r24;
	mov.u32 	%r40, 0;

BB0_1:
	mul.wide.s32 	%rd26, %r38, 4;
	add.s64 	%rd9, %rd7, %rd26;
	mul.wide.s32 	%rd27, %r39, 4;
	add.s64 	%rd10, %rd6, %rd27;
	add.s64 	%rd11, %rd5, %rd26;
	ld.global.nc.f32 	%f3, [%rd11];
	ld.global.nc.f32 	%f4, [%rd10];
	mul.f32 	%f5, %f4, %f3;
	ld.global.nc.f32 	%f6, [%rd9];
	fma.rn.f32 	%f7, %f5, 0f3B800000, %f6;
	add.s64 	%rd12, %rd4, %rd27;
	ld.global.nc.f32 	%f8, [%rd12];
	add.f32 	%f1, %f8, %f7;
	// inline asm
	{  cvt.rn.f16.f32 %rs1, %f1;}

	// inline asm
	mul.wide.s32 	%rd28, %r38, 2;
	add.s64 	%rd13, %rd3, %rd28;
	ld.global.nc.u16 	%rs4, [%rd13];
	// inline asm
	{add.f16 %rs2,%rs1,%rs4;
}
	// inline asm
	add.s64 	%rd14, %rd2, %rd28;
	st.global.u16 	[%rd14], %rs2;
	mov.f32 	%f2, 0f3FA00000;
	// inline asm
	{  cvt.rn.f16.f32 %rs5, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs6,%rs2,%rs5;
}
	// inline asm
	add.s64 	%rd15, %rd1, %rd28;
	ld.global.nc.u16 	%rs11, [%rd15];
	// inline asm
	{mul.f16 %rs9,%rs6,%rs11;
}
	// inline asm
	add.s64 	%rd16, %rd8, %rd28;
	st.global.u16 	[%rd16], %rs9;
	or.b32  	%r25, %r1, %r40;
	setp.ne.s32	%p2, %r25, 0;
	@%p2 bra 	BB0_3;

	mov.u32 	%r26, 0;
	st.shared.u32 	[%r5], %r26;

BB0_3:
	ld.global.nc.f32 	%f11, [%rd11+16384];
	ld.global.nc.f32 	%f12, [%rd10+32];
	mul.f32 	%f13, %f12, %f11;
	ld.global.nc.f32 	%f14, [%rd9+16384];
	fma.rn.f32 	%f15, %f13, 0f3B800000, %f14;
	ld.global.nc.f32 	%f16, [%rd12+32];
	add.f32 	%f9, %f16, %f15;
	// inline asm
	{  cvt.rn.f16.f32 %rs12, %f9;}

	// inline asm
	ld.global.nc.u16 	%rs15, [%rd13+8192];
	// inline asm
	{add.f16 %rs13,%rs12,%rs15;
}
	// inline asm
	st.global.u16 	[%rd14+8192], %rs13;
	// inline asm
	{  cvt.rn.f16.f32 %rs16, %f2;}

	// inline asm
	// inline asm
	{mul.f16 %rs17,%rs13,%rs16;
}
	// inline asm
	ld.global.nc.u16 	%rs22, [%rd15+8192];
	// inline asm
	{mul.f16 %rs20,%rs17,%rs22;
}
	// inline asm
	st.global.u16 	[%rd16+8192], %rs20;
	add.s32 	%r40, %r40, 2;
	add.s32 	%r39, %r39, 16;
	add.s32 	%r38, %r38, 8192;
	setp.ne.s32	%p3, %r40, 8;
	@%p3 bra 	BB0_1;

	bar.sync 	0;
	add.s32 	%r27, %r7, %r2;
	add.s32 	%r28, %r27, %r3;
	mul.wide.s32 	%rd29, %r28, 2;
	add.s64 	%rd30, %rd8, %rd29;
	ld.global.u16 	%rs23, [%rd30];
	// inline asm
	{  cvt.f32.f16 %f17, %rs23;}

	// inline asm
	add.f32 	%f25, %f17, 0f00000000;
	sub.f32 	%f26, %f25, %f17;
	ld.global.u16 	%rs24, [%rd30+8192];
	// inline asm
	{  cvt.f32.f16 %f18, %rs24;}

	// inline asm
	sub.f32 	%f27, %f18, %f26;
	add.f32 	%f28, %f25, %f27;
	sub.f32 	%f29, %f28, %f25;
	sub.f32 	%f30, %f29, %f27;
	ld.global.u16 	%rs25, [%rd30+16384];
	// inline asm
	{  cvt.f32.f16 %f19, %rs25;}

	// inline asm
	sub.f32 	%f31, %f19, %f30;
	add.f32 	%f32, %f28, %f31;
	sub.f32 	%f33, %f32, %f28;
	sub.f32 	%f34, %f33, %f31;
	ld.global.u16 	%rs26, [%rd30+24576];
	// inline asm
	{  cvt.f32.f16 %f20, %rs26;}

	// inline asm
	sub.f32 	%f35, %f20, %f34;
	add.f32 	%f36, %f32, %f35;
	sub.f32 	%f37, %f36, %f32;
	sub.f32 	%f38, %f37, %f35;
	ld.global.u16 	%rs27, [%rd30+32768];
	// inline asm
	{  cvt.f32.f16 %f21, %rs27;}

	// inline asm
	sub.f32 	%f39, %f21, %f38;
	add.f32 	%f40, %f36, %f39;
	sub.f32 	%f41, %f40, %f36;
	sub.f32 	%f42, %f41, %f39;
	ld.global.u16 	%rs28, [%rd30+40960];
	// inline asm
	{  cvt.f32.f16 %f22, %rs28;}

	// inline asm
	sub.f32 	%f43, %f22, %f42;
	add.f32 	%f44, %f40, %f43;
	sub.f32 	%f45, %f44, %f40;
	sub.f32 	%f46, %f45, %f43;
	ld.global.u16 	%rs29, [%rd30+49152];
	// inline asm
	{  cvt.f32.f16 %f23, %rs29;}

	// inline asm
	sub.f32 	%f47, %f23, %f46;
	add.f32 	%f48, %f44, %f47;
	sub.f32 	%f49, %f48, %f44;
	sub.f32 	%f50, %f49, %f47;
	ld.global.u16 	%rs30, [%rd30+57344];
	// inline asm
	{  cvt.f32.f16 %f24, %rs30;}

	// inline asm
	sub.f32 	%f51, %f24, %f50;
	add.f32 	%f52, %f48, %f51;
	mov.u32 	%r29, %ntid.x;
	mad.lo.s32 	%r15, %r29, %r1, %r4;
	and.b32  	%r16, %r15, 127;
	shr.u32 	%r17, %r15, 7;
	shl.b32 	%r30, %r17, 7;
	add.s32 	%r31, %r30, %r16;
	shl.b32 	%r32, %r31, 2;
	mov.u32 	%r33, _ZZ88Fused_Mul_Mul_Add_Add_Cast_Add_Mul_Mul_Cast_ReduceSum_split_13822113215520442086_kernel0E8red_buf0;
	add.s32 	%r18, %r33, %r32;
	st.shared.f32 	[%r18], %f52;
	bar.sync 	0;
	setp.gt.u32	%p4, %r15, 511;
	@%p4 bra 	BB0_6;

	ld.shared.f32 	%f53, [%r18];
	ld.shared.f32 	%f54, [%r18+2048];
	add.f32 	%f55, %f53, %f54;
	st.shared.f32 	[%r18], %f55;

BB0_6:
	bar.sync 	0;
	setp.gt.u32	%p5, %r15, 255;
	@%p5 bra 	BB0_8;

	ld.shared.f32 	%f56, [%r18];
	ld.shared.f32 	%f57, [%r18+1024];
	add.f32 	%f58, %f56, %f57;
	st.shared.f32 	[%r18], %f58;

BB0_8:
	bar.sync 	0;
	setp.ne.s32	%p6, %r17, 0;
	@%p6 bra 	BB0_10;

	ld.shared.f32 	%f59, [%r18];
	ld.shared.f32 	%f60, [%r18+512];
	add.f32 	%f61, %f59, %f60;
	st.shared.f32 	[%r18], %f61;

BB0_10:
	setp.eq.s32	%p1, %r17, 0;
	bar.sync 	0;
	@!%p1 bra 	BB0_12;
	bra.uni 	BB0_11;

BB0_11:
	ld.shared.f32 	%f62, [%r5];
	shl.b32 	%r34, %r16, 2;
	add.s32 	%r36, %r33, %r34;
	ld.shared.f32 	%f63, [%r36];
	add.f32 	%f64, %f62, %f63;
	st.shared.f32 	[%r5], %f64;

BB0_12:
	bar.sync 	0;
	setp.ne.s32	%p7, %r1, 0;
	@%p7 bra 	BB0_14;

	ld.shared.f32 	%f65, [%r5];
	add.s32 	%r37, %r3, %r4;
	cvta.to.global.u64 	%rd31, %rd17;
	mul.wide.s32 	%rd32, %r37, 4;
	add.s64 	%rd33, %rd31, %rd32;
	atom.global.add.f32 	%f66, [%rd33], %f65;

BB0_14:
	bar.sync 	0;
	ret;
}


