//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0
// _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared has been demoted
// _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E8red_buf0 has been demoted

.visible .entry Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0(
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_0,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_1,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_2,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_3,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_4,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_5,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_6,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_7,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_8,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_9,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_10,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_11,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_12,
	.param .u64 Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_13
)
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<85>;
	.reg .f32 	%f<74>;
	.reg .b32 	%r<73>;
	.reg .b64 	%rd<54>;
	// demoted variable
	.shared .align 4 .b8 _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared[512];
	// demoted variable
	.shared .align 4 .b8 _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E8red_buf0[4096];

	ld.param.u64 	%rd14, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_2];
	ld.param.u64 	%rd15, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_3];
	ld.param.u64 	%rd22, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_4];
	ld.param.u64 	%rd23, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_5];
	ld.param.u64 	%rd24, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_6];
	ld.param.u64 	%rd18, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_10];
	ld.param.u64 	%rd19, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_11];
	ld.param.u64 	%rd20, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_12];
	cvta.to.global.u64 	%rd1, %rd22;
	cvta.to.global.u64 	%rd2, %rd24;
	cvta.to.global.u64 	%rd3, %rd23;
	mov.u32 	%r1, %tid.x;
	add.s32 	%r21, %r1, 127;
	shr.s32 	%r22, %r1, 31;
	shr.u32 	%r23, %r22, 25;
	add.s32 	%r24, %r1, %r23;
	and.b32  	%r25, %r24, 1073741696;
	sub.s32 	%r26, %r1, %r25;
	shl.b32 	%r27, %r26, 2;
	mov.u32 	%r28, _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared;
	add.s32 	%r2, %r28, %r27;
	setp.gt.u32	%p2, %r21, 254;
	@%p2 bra 	BB0_2;

	mov.u32 	%r29, 0;
	st.shared.u32 	[%r2], %r29;

BB0_2:
	and.b32  	%r33, %r24, -128;
	sub.s32 	%r3, %r1, %r33;
	bar.sync 	0;
	mov.u32 	%r4, %ctaid.x;
	shl.b32 	%r34, %r4, 15;
	shr.s32 	%r5, %r24, 7;
	shl.b32 	%r38, %r5, 9;
	mov.u32 	%r6, %ctaid.y;
	shl.b32 	%r7, %r6, 7;
	add.s32 	%r39, %r3, %r34;
	add.s32 	%r40, %r39, %r38;
	add.s32 	%r41, %r40, %r7;
	mul.wide.s32 	%rd25, %r41, 2;
	add.s64 	%rd26, %rd3, %rd25;
	ld.global.nc.u16 	%rs2, [%rd26];
	add.s64 	%rd27, %rd2, %rd25;
	ld.global.nc.u16 	%rs3, [%rd27];
	// inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// inline asm
	add.s64 	%rd28, %rd1, %rd25;
	ld.global.nc.u16 	%rs6, [%rd28];
	// inline asm
	{add.f16 %rs4,%rs1,%rs6;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f2, %rs4;}

	// inline asm
	add.f32 	%f10, %f2, 0f00000000;
	sub.f32 	%f11, %f10, %f2;
	ld.global.nc.u16 	%rs9, [%rd26+8192];
	ld.global.nc.u16 	%rs10, [%rd27+8192];
	// inline asm
	{add.f16 %rs8,%rs9,%rs10;
}
	// inline asm
	ld.global.nc.u16 	%rs13, [%rd28+8192];
	// inline asm
	{add.f16 %rs11,%rs8,%rs13;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f3, %rs11;}

	// inline asm
	sub.f32 	%f12, %f3, %f11;
	add.f32 	%f13, %f10, %f12;
	sub.f32 	%f14, %f13, %f10;
	sub.f32 	%f15, %f14, %f12;
	ld.global.nc.u16 	%rs16, [%rd26+16384];
	ld.global.nc.u16 	%rs17, [%rd27+16384];
	// inline asm
	{add.f16 %rs15,%rs16,%rs17;
}
	// inline asm
	ld.global.nc.u16 	%rs20, [%rd28+16384];
	// inline asm
	{add.f16 %rs18,%rs15,%rs20;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f4, %rs18;}

	// inline asm
	sub.f32 	%f16, %f4, %f15;
	add.f32 	%f17, %f13, %f16;
	sub.f32 	%f18, %f17, %f13;
	sub.f32 	%f19, %f18, %f16;
	ld.global.nc.u16 	%rs23, [%rd26+24576];
	ld.global.nc.u16 	%rs24, [%rd27+24576];
	// inline asm
	{add.f16 %rs22,%rs23,%rs24;
}
	// inline asm
	ld.global.nc.u16 	%rs27, [%rd28+24576];
	// inline asm
	{add.f16 %rs25,%rs22,%rs27;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f5, %rs25;}

	// inline asm
	sub.f32 	%f20, %f5, %f19;
	add.f32 	%f21, %f17, %f20;
	sub.f32 	%f22, %f21, %f17;
	sub.f32 	%f23, %f22, %f20;
	ld.global.nc.u16 	%rs30, [%rd26+32768];
	ld.global.nc.u16 	%rs31, [%rd27+32768];
	// inline asm
	{add.f16 %rs29,%rs30,%rs31;
}
	// inline asm
	ld.global.nc.u16 	%rs34, [%rd28+32768];
	// inline asm
	{add.f16 %rs32,%rs29,%rs34;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f6, %rs32;}

	// inline asm
	sub.f32 	%f24, %f6, %f23;
	add.f32 	%f25, %f21, %f24;
	sub.f32 	%f26, %f25, %f21;
	sub.f32 	%f27, %f26, %f24;
	ld.global.nc.u16 	%rs37, [%rd26+40960];
	ld.global.nc.u16 	%rs38, [%rd27+40960];
	// inline asm
	{add.f16 %rs36,%rs37,%rs38;
}
	// inline asm
	ld.global.nc.u16 	%rs41, [%rd28+40960];
	// inline asm
	{add.f16 %rs39,%rs36,%rs41;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f7, %rs39;}

	// inline asm
	sub.f32 	%f28, %f7, %f27;
	add.f32 	%f29, %f25, %f28;
	sub.f32 	%f30, %f29, %f25;
	sub.f32 	%f31, %f30, %f28;
	ld.global.nc.u16 	%rs44, [%rd26+49152];
	ld.global.nc.u16 	%rs45, [%rd27+49152];
	// inline asm
	{add.f16 %rs43,%rs44,%rs45;
}
	// inline asm
	ld.global.nc.u16 	%rs48, [%rd28+49152];
	// inline asm
	{add.f16 %rs46,%rs43,%rs48;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f8, %rs46;}

	// inline asm
	sub.f32 	%f32, %f8, %f31;
	add.f32 	%f33, %f29, %f32;
	sub.f32 	%f34, %f33, %f29;
	sub.f32 	%f35, %f34, %f32;
	ld.global.nc.u16 	%rs51, [%rd26+57344];
	ld.global.nc.u16 	%rs52, [%rd27+57344];
	// inline asm
	{add.f16 %rs50,%rs51,%rs52;
}
	// inline asm
	ld.global.nc.u16 	%rs55, [%rd28+57344];
	// inline asm
	{add.f16 %rs53,%rs50,%rs55;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f9, %rs53;}

	// inline asm
	sub.f32 	%f36, %f9, %f35;
	add.f32 	%f37, %f33, %f36;
	mov.u32 	%r42, %tid.y;
	mov.u32 	%r43, %ntid.x;
	mad.lo.s32 	%r8, %r42, %r43, %r1;
	and.b32  	%r9, %r8, 127;
	shr.u32 	%r10, %r8, 7;
	shl.b32 	%r44, %r10, 7;
	add.s32 	%r45, %r44, %r9;
	shl.b32 	%r46, %r45, 2;
	mov.u32 	%r47, _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E8red_buf0;
	add.s32 	%r11, %r47, %r46;
	st.shared.f32 	[%r11], %f37;
	bar.sync 	0;
	setp.gt.u32	%p3, %r8, 511;
	@%p3 bra 	BB0_4;

	ld.shared.f32 	%f38, [%r11];
	ld.shared.f32 	%f39, [%r11+2048];
	add.f32 	%f40, %f38, %f39;
	st.shared.f32 	[%r11], %f40;

BB0_4:
	bar.sync 	0;
	setp.gt.u32	%p4, %r8, 255;
	@%p4 bra 	BB0_6;

	ld.shared.f32 	%f41, [%r11];
	ld.shared.f32 	%f42, [%r11+1024];
	add.f32 	%f43, %f41, %f42;
	st.shared.f32 	[%r11], %f43;

BB0_6:
	bar.sync 	0;
	setp.ne.s32	%p5, %r10, 0;
	@%p5 bra 	BB0_8;

	ld.shared.f32 	%f44, [%r11];
	ld.shared.f32 	%f45, [%r11+512];
	add.f32 	%f46, %f44, %f45;
	st.shared.f32 	[%r11], %f46;

BB0_8:
	setp.eq.s32	%p1, %r10, 0;
	bar.sync 	0;
	@!%p1 bra 	BB0_10;
	bra.uni 	BB0_9;

BB0_9:
	mov.u32 	%r69, _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E8red_buf0;
	ld.shared.f32 	%f47, [%r2];
	shl.b32 	%r48, %r9, 2;
	add.s32 	%r50, %r69, %r48;
	ld.shared.f32 	%f48, [%r50];
	add.f32 	%f49, %f47, %f48;
	st.shared.f32 	[%r2], %f49;

BB0_10:
	bar.sync 	0;
	setp.gt.s32	%p6, %r1, 127;
	@%p6 bra 	BB0_12;

	ld.param.u64 	%rd53, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_7];
	mov.u32 	%r68, %ctaid.y;
	shl.b32 	%r67, %r68, 7;
	mov.u32 	%r66, _ZZ87Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0E53T_cast_T_add_T_add_input_0_input_1_input_3_red_shared;
	shl.b32 	%r51, %r1, 2;
	add.s32 	%r53, %r66, %r51;
	ld.shared.f32 	%f50, [%r53];
	add.s32 	%r54, %r67, %r1;
	cvta.to.global.u64 	%rd29, %rd53;
	mul.wide.s32 	%rd30, %r54, 4;
	add.s64 	%rd31, %rd29, %rd30;
	atom.global.add.f32 	%f51, [%rd31], %f50;

BB0_12:
	bar.sync 	0;
	setp.gt.s32	%p7, %r3, 2;
	@%p7 bra 	BB0_16;

	mov.u32 	%r58, %ctaid.x;
	mad.lo.s32 	%r12, %r58, 3, %r3;
	setp.gt.s32	%p8, %r12, 511;
	@%p8 bra 	BB0_16;

	mov.u32 	%r65, %tid.x;
	ld.param.u64 	%rd52, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_0];
	ld.param.u64 	%rd51, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_9];
	ld.param.u64 	%rd50, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_13];
	shr.s32 	%r64, %r65, 31;
	shr.u32 	%r63, %r64, 25;
	add.s32 	%r62, %r65, %r63;
	shr.s32 	%r61, %r62, 7;
	mov.u32 	%r60, %ctaid.y;
	ld.param.u64 	%rd49, [Fused_Add_Add_Cast_ReduceSum_Sub_Mul_Mul_Mul_Mul_Mul_split_17004516953336970423_kernel0_param_1];
	mov.u32 	%r59, %ctaid.x;
	cvta.to.global.u64 	%rd32, %rd49;
	mul.wide.s32 	%rd33, %r12, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	mad.lo.s32 	%r71, %r60, 3072, %r61;
	mad.lo.s32 	%r56, %r60, 1572864, %r3;
	mad.lo.s32 	%r57, %r61, 512, %r56;
	mad.lo.s32 	%r70, %r59, 3, %r57;
	cvta.to.global.u64 	%rd4, %rd50;
	cvta.to.global.u64 	%rd5, %rd51;
	cvta.to.global.u64 	%rd6, %rd52;
	cvta.to.global.u64 	%rd7, %rd18;
	cvta.to.global.u64 	%rd8, %rd20;
	cvta.to.global.u64 	%rd9, %rd15;
	cvta.to.global.u64 	%rd10, %rd14;
	cvta.to.global.u64 	%rd11, %rd19;
	mov.u32 	%r72, -384;

BB0_15:
	mul.wide.s32 	%rd35, %r70, 2;
	add.s64 	%rd36, %rd3, %rd35;
	ld.global.nc.u16 	%rs58, [%rd36];
	add.s64 	%rd37, %rd2, %rd35;
	ld.global.nc.u16 	%rs59, [%rd37];
	// inline asm
	{add.f16 %rs57,%rs58,%rs59;
}
	// inline asm
	add.s64 	%rd38, %rd1, %rd35;
	ld.global.nc.u16 	%rs62, [%rd38];
	// inline asm
	{add.f16 %rs60,%rs57,%rs62;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f52, %rs60;}

	// inline asm
	mul.f32 	%f56, %f52, %f1;
	mul.wide.s32 	%rd39, %r70, 4;
	add.s64 	%rd40, %rd11, %rd39;
	st.global.f32 	[%rd40], %f56;
	add.s64 	%rd41, %rd10, %rd39;
	mul.wide.s32 	%rd42, %r71, 4;
	add.s64 	%rd43, %rd9, %rd42;
	ld.global.nc.f32 	%f57, [%rd43];
	ld.global.nc.f32 	%f58, [%rd41];
	sub.f32 	%f59, %f58, %f57;
	add.s64 	%rd44, %rd8, %rd39;
	st.global.f32 	[%rd44], %f59;
	mul.f32 	%f60, %f56, %f59;
	add.s64 	%rd45, %rd7, %rd39;
	st.global.f32 	[%rd45], %f60;
	// inline asm
	{add.f16 %rs64,%rs58,%rs59;
}
	// inline asm
	// inline asm
	{add.f16 %rs67,%rs64,%rs62;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f53, %rs67;}

	// inline asm
	add.s64 	%rd46, %rd6, %rd42;
	ld.global.nc.f32 	%f61, [%rd46];
	mul.f32 	%f62, %f61, %f59;
	mul.f32 	%f63, %f53, %f62;
	add.s64 	%rd47, %rd5, %rd39;
	st.global.f32 	[%rd47], %f63;
	mul.f32 	%f64, %f56, %f61;
	add.s64 	%rd48, %rd4, %rd39;
	st.global.f32 	[%rd48], %f64;
	ld.global.nc.u16 	%rs72, [%rd36+8192];
	ld.global.nc.u16 	%rs73, [%rd37+8192];
	// inline asm
	{add.f16 %rs71,%rs72,%rs73;
}
	// inline asm
	ld.global.nc.u16 	%rs76, [%rd38+8192];
	// inline asm
	{add.f16 %rs74,%rs71,%rs76;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f54, %rs74;}

	// inline asm
	mul.f32 	%f65, %f54, %f1;
	st.global.f32 	[%rd40+16384], %f65;
	ld.global.nc.f32 	%f66, [%rd43+32];
	ld.global.nc.f32 	%f67, [%rd41+16384];
	sub.f32 	%f68, %f67, %f66;
	st.global.f32 	[%rd44+16384], %f68;
	mul.f32 	%f69, %f65, %f68;
	st.global.f32 	[%rd45+16384], %f69;
	// inline asm
	{add.f16 %rs78,%rs72,%rs73;
}
	// inline asm
	// inline asm
	{add.f16 %rs81,%rs78,%rs76;
}
	// inline asm
	// inline asm
	{  cvt.f32.f16 %f55, %rs81;}

	// inline asm
	ld.global.nc.f32 	%f70, [%rd46+32];
	mul.f32 	%f71, %f70, %f68;
	mul.f32 	%f72, %f55, %f71;
	st.global.f32 	[%rd47+16384], %f72;
	mul.f32 	%f73, %f65, %f70;
	st.global.f32 	[%rd48+16384], %f73;
	add.s32 	%r71, %r71, 16;
	add.s32 	%r70, %r70, 8192;
	add.s32 	%r72, %r72, 2;
	setp.ne.s32	%p9, %r72, 0;
	@%p9 bra 	BB0_15;

BB0_16:
	ret;
}


