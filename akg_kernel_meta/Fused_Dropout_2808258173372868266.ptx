//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Dropout_2808258173372868266_kernel0

.visible .entry Fused_Dropout_2808258173372868266_kernel0(
	.param .u64 Fused_Dropout_2808258173372868266_kernel0_param_0,
	.param .u64 Fused_Dropout_2808258173372868266_kernel0_param_1,
	.param .u64 Fused_Dropout_2808258173372868266_kernel0_param_2,
	.param .u64 Fused_Dropout_2808258173372868266_kernel0_param_3
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<169>;
	.reg .f32 	%f<49>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [Fused_Dropout_2808258173372868266_kernel0_param_0];
	ld.param.u64 	%rd2, [Fused_Dropout_2808258173372868266_kernel0_param_1];
	ld.param.u64 	%rd3, [Fused_Dropout_2808258173372868266_kernel0_param_2];
	ld.param.u64 	%rd4, [Fused_Dropout_2808258173372868266_kernel0_param_3];
	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd6, %rd4;
	cvta.to.global.u64 	%rd7, %rd1;
	cvta.to.global.u64 	%rd8, %rd2;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %tid.x;
	shl.b32 	%r15, %r14, 2;
	mad.lo.s32 	%r16, %r13, 6144, %r15;
	mul.wide.s32 	%rd9, %r16, 4;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.nc.v4.f32 	{%f37, %f38, %f39, %f40}, [%rd10];
	mul.wide.s32 	%rd11, %r16, 2;
	add.s64 	%rd12, %rd7, %rd11;
	ld.global.nc.v4.u16 	{%rs157, %rs158, %rs159, %rs160}, [%rd12];
	// inline asm
	{  cvt.rn.f16.f32 %rs1, %f37;}

	// inline asm
	mov.f32 	%f35, 0f3F4CC000;
	// inline asm
	{  cvt.rn.f16.f32 %rs2, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs1, %rs2;
  selp.u16 %rs3, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p1, %rs3, 0;
	selp.u32	%r1, 1, 0, %p1;
	mov.f32 	%f36, 0f3FA00000;
	// inline asm
	{  cvt.rn.f16.f32 %rs7, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs8,%rs157,%rs7;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs14, %f38;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs15, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs14, %rs15;
  selp.u16 %rs16, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p2, %rs16, 0;
	selp.u32	%r2, 1, 0, %p2;
	// inline asm
	{  cvt.rn.f16.f32 %rs20, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs21,%rs158,%rs20;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs27, %f39;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs28, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs27, %rs28;
  selp.u16 %rs29, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p3, %rs29, 0;
	selp.u32	%r3, 1, 0, %p3;
	// inline asm
	{  cvt.rn.f16.f32 %rs33, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs34,%rs159,%rs33;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs40, %f40;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs41, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs40, %rs41;
  selp.u16 %rs42, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p4, %rs42, 0;
	selp.u32	%r4, 1, 0, %p4;
	// inline asm
	{  cvt.rn.f16.f32 %rs46, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs47,%rs160,%rs46;
}
	// inline asm
	add.s64 	%rd13, %rd6, %rd11;
	// inline asm
	cvt.rn.f16.s32 %rs45, %r4;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs32, %r3;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs19, %r2;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs6, %r1;
	// inline asm
	st.global.v4.u16 	[%rd13], {%rs6, %rs19, %rs32, %rs45};
	add.s64 	%rd14, %rd5, %rd11;
	// inline asm
	{mul.f16 %rs50,%rs47,%rs45;
}
	// inline asm
	// inline asm
	{mul.f16 %rs37,%rs34,%rs32;
}
	// inline asm
	// inline asm
	{mul.f16 %rs24,%rs21,%rs19;
}
	// inline asm
	// inline asm
	{mul.f16 %rs11,%rs8,%rs6;
}
	// inline asm
	st.global.v4.u16 	[%rd14], {%rs11, %rs24, %rs37, %rs50};
	ld.global.nc.v4.f32 	{%f41, %f42, %f43, %f44}, [%rd10+8192];
	ld.global.nc.v4.u16 	{%rs161, %rs162, %rs163, %rs164}, [%rd12+4096];
	// inline asm
	{  cvt.rn.f16.f32 %rs53, %f41;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs54, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs53, %rs54;
  selp.u16 %rs55, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p5, %rs55, 0;
	selp.u32	%r5, 1, 0, %p5;
	// inline asm
	{  cvt.rn.f16.f32 %rs59, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs60,%rs161,%rs59;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs66, %f42;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs67, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs66, %rs67;
  selp.u16 %rs68, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p6, %rs68, 0;
	selp.u32	%r6, 1, 0, %p6;
	// inline asm
	{  cvt.rn.f16.f32 %rs72, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs73,%rs162,%rs72;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs79, %f43;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs80, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs79, %rs80;
  selp.u16 %rs81, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p7, %rs81, 0;
	selp.u32	%r7, 1, 0, %p7;
	// inline asm
	{  cvt.rn.f16.f32 %rs85, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs86,%rs163,%rs85;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs92, %f44;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs93, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs92, %rs93;
  selp.u16 %rs94, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p8, %rs94, 0;
	selp.u32	%r8, 1, 0, %p8;
	// inline asm
	{  cvt.rn.f16.f32 %rs98, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs99,%rs164,%rs98;
}
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs97, %r8;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs84, %r7;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs71, %r6;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs58, %r5;
	// inline asm
	st.global.v4.u16 	[%rd13+4096], {%rs58, %rs71, %rs84, %rs97};
	// inline asm
	{mul.f16 %rs102,%rs99,%rs97;
}
	// inline asm
	// inline asm
	{mul.f16 %rs89,%rs86,%rs84;
}
	// inline asm
	// inline asm
	{mul.f16 %rs76,%rs73,%rs71;
}
	// inline asm
	// inline asm
	{mul.f16 %rs63,%rs60,%rs58;
}
	// inline asm
	st.global.v4.u16 	[%rd14+4096], {%rs63, %rs76, %rs89, %rs102};
	ld.global.nc.v4.f32 	{%f45, %f46, %f47, %f48}, [%rd10+16384];
	ld.global.nc.v4.u16 	{%rs165, %rs166, %rs167, %rs168}, [%rd12+8192];
	// inline asm
	{  cvt.rn.f16.f32 %rs105, %f45;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs106, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs105, %rs106;
  selp.u16 %rs107, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p9, %rs107, 0;
	selp.u32	%r9, 1, 0, %p9;
	// inline asm
	{  cvt.rn.f16.f32 %rs111, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs112,%rs165,%rs111;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs118, %f46;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs119, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs118, %rs119;
  selp.u16 %rs120, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p10, %rs120, 0;
	selp.u32	%r10, 1, 0, %p10;
	// inline asm
	{  cvt.rn.f16.f32 %rs124, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs125,%rs166,%rs124;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs131, %f47;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs132, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs131, %rs132;
  selp.u16 %rs133, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p11, %rs133, 0;
	selp.u32	%r11, 1, 0, %p11;
	// inline asm
	{  cvt.rn.f16.f32 %rs137, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs138,%rs167,%rs137;
}
	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs144, %f48;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs145, %f35;}

	// inline asm
	// inline asm
	{ .reg .pred __$temp3;
  setp.le.f16  __$temp3, %rs144, %rs145;
  selp.u16 %rs146, 1, 0, __$temp3;}
	// inline asm
	setp.ne.s16	%p12, %rs146, 0;
	selp.u32	%r12, 1, 0, %p12;
	// inline asm
	{  cvt.rn.f16.f32 %rs150, %f36;}

	// inline asm
	// inline asm
	{mul.f16 %rs151,%rs168,%rs150;
}
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs149, %r12;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs136, %r11;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs123, %r10;
	// inline asm
	// inline asm
	cvt.rn.f16.s32 %rs110, %r9;
	// inline asm
	st.global.v4.u16 	[%rd13+8192], {%rs110, %rs123, %rs136, %rs149};
	// inline asm
	{mul.f16 %rs154,%rs151,%rs149;
}
	// inline asm
	// inline asm
	{mul.f16 %rs141,%rs138,%rs136;
}
	// inline asm
	// inline asm
	{mul.f16 %rs128,%rs125,%rs123;
}
	// inline asm
	// inline asm
	{mul.f16 %rs115,%rs112,%rs110;
}
	// inline asm
	st.global.v4.u16 	[%rd14+8192], {%rs115, %rs128, %rs141, %rs154};
	ret;
}


