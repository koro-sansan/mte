//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29190527
// Cuda compilation tools, release 11.1, V11.1.105
// Based on LLVM 3.4svn
//

.version 7.1
.target sm_80
.address_size 64

	// .globl	Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0

.visible .entry Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0(
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_0,
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_1,
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_2,
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_3,
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_4,
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_5,
	.param .u64 Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_6
)
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<33>;
	.reg .f32 	%f<81>;
	.reg .b32 	%r<74>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd8, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_0];
	ld.param.u64 	%rd2, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_1];
	ld.param.u64 	%rd3, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_2];
	ld.param.u64 	%rd4, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_3];
	ld.param.u64 	%rd5, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_4];
	ld.param.u64 	%rd6, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_5];
	ld.param.u64 	%rd7, [Fused_Reshape_Mul_Reshape_Add_Cast_Reshape_Cast_Reshape_split_Reshape_Mul_Res_more_parallel_13881563296994797575_kernel0_param_6];
	mov.u32 	%r1, %ctaid.x;
	setp.lt.s32	%p1, %r1, 6144;
	mul.hi.s32 	%r8, %r1, 715827883;
	shr.u32 	%r9, %r8, 31;
	shr.s32 	%r10, %r8, 10;
	add.s32 	%r11, %r10, %r9;
	mul.lo.s32 	%r12, %r11, 6144;
	sub.s32 	%r13, %r1, %r12;
	shr.s32 	%r14, %r13, 31;
	shr.u32 	%r15, %r14, 23;
	add.s32 	%r16, %r13, %r15;
	shl.b32 	%r17, %r16, 13;
	and.b32  	%r2, %r17, -4194304;
	mov.u32 	%r18, %tid.x;
	shr.s32 	%r19, %r18, 31;
	shr.u32 	%r20, %r19, 22;
	add.s32 	%r21, %r18, %r20;
	and.b32  	%r22, %r21, -1024;
	sub.s32 	%r23, %r18, %r22;
	shr.s32 	%r24, %r23, 31;
	shr.u32 	%r25, %r24, 24;
	add.s32 	%r26, %r23, %r25;
	shl.b32 	%r27, %r26, 11;
	and.b32  	%r3, %r27, -524288;
	and.b32  	%r28, %r26, 1073741568;
	sub.s32 	%r29, %r23, %r28;
	shl.b32 	%r4, %r29, 2;
	shr.s32 	%r30, %r1, 31;
	shr.u32 	%r31, %r30, 23;
	add.s32 	%r32, %r1, %r31;
	and.b32  	%r33, %r32, 4193792;
	sub.s32 	%r34, %r1, %r33;
	shl.b32 	%r5, %r34, 10;
	shr.u32 	%r35, %r19, 24;
	add.s32 	%r36, %r18, %r35;
	and.b32  	%r37, %r36, 1073741568;
	sub.s32 	%r38, %r18, %r37;
	shl.b32 	%r39, %r38, 2;
	add.s32 	%r6, %r39, %r5;
	cvta.to.global.u64 	%rd9, %rd8;
	mul.wide.s32 	%rd10, %r6, 4;
	add.s64 	%rd1, %rd9, %rd10;
	shl.b32 	%r40, %r36, 11;
	and.b32  	%r7, %r40, -524288;
	@%p1 bra 	BB0_2;
	bra.uni 	BB0_1;

BB0_2:
	ld.global.nc.v4.f32 	{%f57, %f58, %f59, %f60}, [%rd1];
	shl.b32 	%r67, %r32, 13;
	and.b32  	%r68, %r67, -4194304;
	add.s32 	%r69, %r6, %r68;
	add.s32 	%r70, %r69, %r7;
	cvta.to.global.u64 	%rd20, %rd2;
	mul.wide.s32 	%rd21, %r70, 4;
	add.s64 	%rd22, %rd20, %rd21;
	ld.global.nc.v4.f32 	{%f65, %f66, %f67, %f68}, [%rd22];
	fma.rn.f32 	%f41, %f65, 0f42000000, %f57;
	fma.rn.f32 	%f43, %f66, 0f42000000, %f58;
	fma.rn.f32 	%f45, %f67, 0f42000000, %f59;
	fma.rn.f32 	%f47, %f68, 0f42000000, %f60;
	add.s32 	%r71, %r5, %r2;
	add.s32 	%r72, %r71, %r3;
	add.s32 	%r73, %r72, %r4;
	cvta.to.global.u64 	%rd23, %rd5;
	mul.wide.s32 	%rd24, %r73, 2;
	add.s64 	%rd25, %rd23, %rd24;
	// inline asm
	{  cvt.rn.f16.f32 %rs23, %f47;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs21, %f45;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs19, %f43;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs17, %f41;}

	// inline asm
	st.global.v4.u16 	[%rd25], {%rs17, %rs19, %rs21, %rs23};
	cvta.to.global.u64 	%rd26, %rd4;
	mul.wide.s32 	%rd27, %r73, 4;
	add.s64 	%rd28, %rd26, %rd27;
	// inline asm
	{  cvt.f32.f16 %f48, %rs23;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f46, %rs21;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f44, %rs19;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f42, %rs17;}

	// inline asm
	st.global.v4.f32 	[%rd28], {%f42, %f44, %f46, %f48};
	ld.global.nc.v4.f32 	{%f73, %f74, %f75, %f76}, [%rd22+8388608];
	fma.rn.f32 	%f49, %f73, 0f42000000, %f57;
	fma.rn.f32 	%f51, %f74, 0f42000000, %f58;
	fma.rn.f32 	%f53, %f75, 0f42000000, %f59;
	fma.rn.f32 	%f55, %f76, 0f42000000, %f60;
	// inline asm
	{  cvt.rn.f16.f32 %rs31, %f55;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs29, %f53;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs27, %f51;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs25, %f49;}

	// inline asm
	st.global.v4.u16 	[%rd25+4194304], {%rs25, %rs27, %rs29, %rs31};
	// inline asm
	{  cvt.f32.f16 %f56, %rs31;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f54, %rs29;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f52, %rs27;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f50, %rs25;}

	// inline asm
	st.global.v4.f32 	[%rd28+8388608], {%f50, %f52, %f54, %f56};
	bra.uni 	BB0_3;

BB0_1:
	add.s32 	%r41, %r1, -6144;
	mul.hi.s32 	%r42, %r41, 715827883;
	shr.u32 	%r43, %r42, 31;
	shr.s32 	%r44, %r42, 10;
	add.s32 	%r45, %r44, %r43;
	mul.lo.s32 	%r46, %r45, 6144;
	sub.s32 	%r47, %r41, %r46;
	shr.s32 	%r48, %r47, 31;
	shr.u32 	%r49, %r48, 23;
	add.s32 	%r50, %r47, %r49;
	shl.b32 	%r51, %r50, 13;
	and.b32  	%r52, %r51, -4194304;
	ld.global.nc.v4.f32 	{%f17, %f18, %f19, %f20}, [%rd1];
	shr.s32 	%r53, %r41, 31;
	shr.u32 	%r54, %r53, 23;
	add.s32 	%r55, %r41, %r54;
	and.b32  	%r56, %r55, 4193792;
	sub.s32 	%r57, %r41, %r56;
	shl.b32 	%r58, %r57, 10;
	add.s32 	%r59, %r2, %r7;
	add.s32 	%r60, %r6, %r59;
	cvta.to.global.u64 	%rd11, %rd3;
	mul.wide.s32 	%rd12, %r60, 4;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.nc.v4.f32 	{%f25, %f26, %f27, %f28}, [%rd13];
	fma.rn.f32 	%f1, %f25, 0f42000000, %f17;
	fma.rn.f32 	%f3, %f26, 0f42000000, %f18;
	fma.rn.f32 	%f5, %f27, 0f42000000, %f19;
	fma.rn.f32 	%f7, %f28, 0f42000000, %f20;
	add.s32 	%r61, %r52, %r3;
	add.s32 	%r62, %r61, %r58;
	add.s32 	%r63, %r62, %r4;
	cvta.to.global.u64 	%rd14, %rd7;
	mul.wide.s32 	%rd15, %r63, 2;
	add.s64 	%rd16, %rd14, %rd15;
	// inline asm
	{  cvt.rn.f16.f32 %rs7, %f7;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs5, %f5;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs3, %f3;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs1, %f1;}

	// inline asm
	st.global.v4.u16 	[%rd16], {%rs1, %rs3, %rs5, %rs7};
	cvta.to.global.u64 	%rd17, %rd6;
	mul.wide.s32 	%rd18, %r63, 4;
	add.s64 	%rd19, %rd17, %rd18;
	// inline asm
	{  cvt.f32.f16 %f8, %rs7;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f6, %rs5;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f4, %rs3;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f2, %rs1;}

	// inline asm
	st.global.v4.f32 	[%rd19], {%f2, %f4, %f6, %f8};
	ld.global.nc.v4.f32 	{%f33, %f34, %f35, %f36}, [%rd13+8388608];
	fma.rn.f32 	%f9, %f33, 0f42000000, %f17;
	fma.rn.f32 	%f11, %f34, 0f42000000, %f18;
	fma.rn.f32 	%f13, %f35, 0f42000000, %f19;
	fma.rn.f32 	%f15, %f36, 0f42000000, %f20;
	// inline asm
	{  cvt.rn.f16.f32 %rs15, %f15;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs13, %f13;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs11, %f11;}

	// inline asm
	// inline asm
	{  cvt.rn.f16.f32 %rs9, %f9;}

	// inline asm
	st.global.v4.u16 	[%rd16+4194304], {%rs9, %rs11, %rs13, %rs15};
	// inline asm
	{  cvt.f32.f16 %f16, %rs15;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f14, %rs13;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f12, %rs11;}

	// inline asm
	// inline asm
	{  cvt.f32.f16 %f10, %rs9;}

	// inline asm
	st.global.v4.f32 	[%rd19+8388608], {%f10, %f12, %f14, %f16};

BB0_3:
	ret;
}


